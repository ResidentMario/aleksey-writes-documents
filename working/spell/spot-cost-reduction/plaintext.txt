 While prices have steadily decreased over time, cloud GPUs remain one of the most expensive compute resources available. If you or your team trains deep learning models on the cloud, you can substantially reduce your monthly bill by switching from basic pay-as-you-go on-demand instances to the more complicated(but also more economical!) spot instances. In this blog post, we will discuss using spot instances for machine learning--what they are, how they work, and why theyâ€™re cheaper than on-demand (and by how much). Weâ€™ll also discuss best practices for performing model training on spot instances, and share how weâ€™ve built spot instance support into our product at Spell.  The simplest way to reserve a compute instance on the cloud is to get it on-demand. Once youâ€™ve requested and received an on-demand instance, itâ€™s yours to keep (at least until it suffers a hardware failure or goes offline for a maintenance event). Spot instances allow you to get the same compute power at a much cheaper price, with the compromise that the cloud provider may terminate your instance at any time. Cloud vendors use spot instances for capacity planning purposes. During periods of high demand, the vendor will shut down some spot instances (or prevent new ones from being spun up) so that the backing machines can be used to fulfill more lucrative on-demand instance requests. During periods of low demand, the large volume of job requests at the lower rate ensures that machines remain in use, continuing to drive revenue. Spot instance interruptions may be more common than on-demand interruptions, but theyâ€™re still rare. AWS and GCP (which uses the term "preemptible instances") both report a metric called frequency of interruption: the percentage of customer job run on spot instances that were interrupted before completion. This statistic varies over time and instance type, but is typically <5% on both clouds for most instances.  The marque feature of spot instances is the potential cost savings. So, how much cheaper? AWS has a built-in price history feature in their web console, which you can use to see up to three months of spot instance prices. To understand how much you could potentially save by using spot instances for your workflows, letâ€™s look at the price histories for three common instance types. Note that each of the graphs that follow are for the us-west-2 region. Here are three months of price history for a p2.xlarge instance, which comes equipped with a K80. The K80 is generally the cheapest GPU available on the cloud, making it a great choice for model prototyping. The straight line near the top of this graph is the p2.xlarge on-demand price: $0.90/hour. There is some long-lived regional variation in the spot price across availability zones, but itâ€™s always between $0.27 and ~$0.35 an hour, and in recent months has flatlined to $0.27/hour. Next up, three months of price history for a p2.8xlarge instance, e.g. a server with eight K80s on it. As you can see, this graph is almost offensively boring: spot instance cost is always a third of the on-demand cost: $4.32/hour versus $14.40/hour. I suspect this is the case because this instance type is actually very rarely used â€” due to the overhead of shuffling memory among eight different GPUs, a K80x8 is much less efficient pound-for-pound (and dollar-for-dollar) than an instance with a smaller number of beefier GPUs, like a V100x4. Speaking of V100s, here is three months of price history for a p3.8xlarge, a compute instance with four V100s attached to it. The V100 is the most recent generation of GPU generally available on the cloud, and this is the second most powerful GPU instance type available on AWS (behind only the p3.16xlarge and its bandwidth-upscaled cousin, the p3dn.24xlarge), a perfect fit for most large single-model training jobs. Once again, costs are almost flat, with a small amount of regional variation, with a floor price of $3.6720/hour. To contextualize how much of a difference this makes, consider the following benchmarks: Cost savings on GCP are similar. Unlike AWS, GCP has a fixed price for their instances â€” the exact discount rate varies from instance to instance but is generally at or near 66%. The price list is available on the page, VM Instance Pricing. Repeating the same benchmarks on GCP: Needless to say, the cost savings are pretty spectacular! ðŸ’¸  Users on our Spell for Teams plan can schedule and execute training jobs on their self-defined instance types. We call this feature machine type management, and itâ€™s an integral part of our product experience. One of the configuration options for new machine types is toggling on spot instances: We use a naive instance scheduling strategy which has worked well for us in practice. We randomly shuffle every availability zone in the region into a list, then go through every availability zone sequentially, asking the cloud provider if a spot instance is available. If it is not (remember, new spot instances are not always available in periods of high demand), we move on to the next availability zone. If none of the availability zones have spot instances available (which is extremely rare), we wait for a bit, then start over again at the top of the list. This strategy is simple because our usersâ€™ needs are simple. Our users are usually data scientists who want to think about the model architecture, not the compute layer. For the most part, they mind waiting an extra five minutes or so for a job to start in a period of high spot demand. For similar reasons, we have not felt the need to implement logic for performing price comparison across availability zones; as the AWS price charts have shown, prices are never out of sync by more than a few cents an hour, so doing so ultimately would not save our users much money. On the other hand, our random selection strategy prevents particularly compute-hungry customers from accidentally raising their own bills by saturating spot availability in a particular zone, reducing availability and increasing prices in the process. Finally, on AWS we use the default max price. In other words, we will never schedule our users on a spot instance costing more than an on-demand instance of the same type.  While spot instances provide attractive cost savings over on-demand instances, they do require some adjustments by the user. First of all, be careful about using spot instances for interactive model work. Although this saves you money in the long run, having the machine shut down in the middle of a Jupyter Notebook session is extremely annoying! Second of all, if you are on GCP, be careful when using preemptible instances for model training jobs lasting over 24 hours. Preemptible instances have an important weakness: they auto-terminate after 24 hours in service. Itâ€™s right there in the docs. In practice, weâ€™ve found GCP preemptible instances to be much flakier than AWS spot instances, often kicking the machine into REPAIRING state right in the middle of a user job without waiting for the user to finish like AWS instances do. To learn more about this, refer to the blog post "Automating GPU machine failure recovery in Google Compute Engine". Finally, when using spot instances, be sure to make your model training scripts reentrant. A training script is reentrant if after being interrupted midway through execution (by a spot interrupt, in this case), it can be restarted using an intermediate checkpoint to continue training. This is essential for machine learning training jobs on spot instances â€” you donâ€™t want to train a promising model for 95% of its epochs, only to have the training job fail with no outputs right before it completes. In most cases, reentrancy is easy to achieve and aligns well with existing best practices around model checkpoints. To learn more, check out our interactive tutorial on the subject. Create an account in minutes or connect with our team to learn how Spell can accelerate your business. Privacy Policy | Terms of Service | Data Processing Addendum Â© Spell 2021. All Rights Reserved. 