missingno (shorthand msno) is a glitch Pokemon. It's also the name of a Python library for the exploratory visualization of missing data. This notebook is an applied example of using missingno to understand how sparse a dataset is. We are using the horse racing dataset: This dataset is in a "long" format, where each tipster gets their own record in the dataset. In order to do any sort of prediction, we probably want to pivot this data to a "wide" format, where each tipster gets their own column. The trouble that we immediately see is that the values in this dataset are highly sparse: there seem to be quite a few NaN values. We can use missingno to see just how sparse. Some of these exchanges are barely reporting anything! Bot for some races, all 31 exchanges are reporting. We can use a bar chart to see how often the various exchanges report: Any model we build (with scikit-learn and so on) will need to be based on non-sparse data. We could fill the values in, but given this level of sparsity, with some exchanges only reporting on 23 races, it's a better idea to just pick a handful of high-volume exchanges. We can use a heatmap to pick up interesting correlations between different exchanges: For example, note how certain exchanges tend to always report on the same races. For example, Tipster T always reports when A is reporting. The same relationship exists behind C1 and B. Meanwhile, tipster C is really independent of all of the other exchanges. We can use a dendrogram, which reports on the closeness of reporting by different exchanges, to see this same information. To build a model, we will need to isolate a subset of these races which all have some subset of tipsters reporting in. This is because models in e.g. scikit-learn do not deal with null values; we have to fill them in or drop them out of consideration. Here's one reasonable choice of exchanges we can make for the purposes of model-building: For sparse datasets, missingno is a pretty nifty tool! If you haven't already, you should consider adding it to your data science workbench. :) 