Corresponding training log: The following generator transform is used: This is a $[0, 1]$ transform (typical for images, which start out $[0, 255]$ per-pixel) with random flips in both directions and random shear. Random shear is appropriate because sheared landscaped still generally look like legitamite landscapes. Flips artificially pad out dataset size. No cropping is applied, which I find interesting...perhaps labels are sensitive to small features in the images, which makes cropping them unsafe? Trick: preprocessing training images with single-image haze removal. This is a technique that comes courtesy of this paper. The difficulty that haze creates for machine learning models is obvious. Haze removal traditionally requires multiple images or depth estimates from the user because the extent of the effect of haze on color contrast is dependent on the distance to the image feature. More recent efforts have been in the space of finding techniques for haze elimination that are single-image. The paper that bestfitting used implements a haze removal algorithm by using what they describe as a "dark channel prior". Basically, the lower the minimum value across color channels of an image, the less hazy that pixel is. This turns out to be a relatively robust measurement of haze because outdoor scenes of the type susceptible to haze naturally have shadows or color, which always correspondings with a low value in at least one color channel (otherwise you get a grayscale image). A haze intensity map is calculated by applying a formula to this dark channel prior, and that map is then itself processed using soft matting to correct edges. Then some additional work is performed to estimate atmospheric light, and the image saturation is recalibrated on a pixel-per-pixel basis to clean up the haze. An easy-to-use Python implementation of the techniques in this paper exists: https://github.com/joyeecheung/dark-channel-prior-dehazing. Trick: Mining images were a common source of difficulty during the competition. bestfitting trained a seperate neural network (based on something called "simplenet", which I can't find reference to online) on the third of the images with the highest loss. This seperate neural net took over the task of classifying these "hard" images. 