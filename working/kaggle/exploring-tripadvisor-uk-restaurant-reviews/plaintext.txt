TripAdvisor is a well-known and well-established website which provides hotel bookings, travel information, and userspace reviews about trip-related content. TripAdvisor is somewhat unusual amongst such sites in that the vast majority of the content on it is user-generated. This dataset is a sample of TripAdvisor restaurant reviews: more specifically, a sample of user restaurant reviews on TripAdvisor Uk, with a particular (but not exclusive) focus on locations in the city of London. We will probe the basic dataset attributes and hopefully uncover some interesting effects from the data! This exploratory data analytics notebook is recommended for beginners. Feel free to fork this notebook and/or copy the code here and explore further on your own!  As usual, we need to do a bit of data processing beforehand to make things neat. When are reviews on TripAdvisor written, by who, and about who? We see above that the same provided in this dataset is biased towards recent reviews, peaking in 2016 (2017 represents less than a full year's worth of data at the time that this sample was taken, but is on track to beat the 2016 total). Is this due to strong growth in the TripAdvisor review platform, or due to some detail of how this data was collected on PromptCloud's side? Can't be too sure. Reviews are randomly distributed across time. I found this surprising, as I expected restaurant reviews to peak in good weather months, particularly in the summer. Finally, we see that both authors and restaurant reviews have a logorithmic shape. A few restaurants have dozens to hundreds or reviews, but the vast majority are in the single digits. Authors are almost all on a single review written total. The paucity of high-numeracy authors is surprising. Let's zoom in on the ratings to see if there any differences between the different categories. My expectation is that section-wise restaurant reviews are going to be very close to overall ratings as a whole. And this is indeed mostly the case. But there's interesting variance at play here: users seems to be consistently overrating Value (how good of a value for its money a restuarant is), while underrating food quality and service quality. This effect is pretty large: a TripAdvisor UK user is about 50% more likely to rate a restaurant as being a good value then to rate it having good service or food. For fun, let's take a look at the words contained in the titles and texts of the reviews. These fields are the true heart of this dataset! For starters, let's examine the most common non-stopwords (e.g. not and, but, or another of the most common adejctives and other supporting words) in the titles of the restaurant reviews in the sample. A little bit of contextual knowledge is necessary to interpret this chart. It's unsurprising but interesting that Restaurant and Bar are out in front, but notice the effect that chain strores like Pret Manger and TGI Friday's has on the results: Pret, Manger, TGI, and Friday's are all (separately) out in front. Still, I wouldn't have guessed that Garden is more common than Park in restaurant names on my own. Are "good" restaurants more common than "great" ones? Let's check some values in the review titles to find out... It seems that "great" is much more popular in review names than "good", suprisingly enough! Meanwhile, reviews badmouthing the restaurant in question seem to be quite rare. We can make a wordcloud out of these words; what pops out there? Nothing much; this wells us about the same thing. Let's do one last thing, just for fun. What meal is more popular, lunch or dinner? Lunch wins! That's all for here, folks! We've only just scratched the surface of what we can do with this data, especially in terms of natural language processing. Here are some more things you can try: 