r/worldnews is a subreddit (and the subject of this dataset) with what is generally considered to be a very, um, "interesting" perspective on things. In less nice terms, it's the echo chamber of the echo chamber of the Internet. At least, that's the common perception. Surely that's something that would show up in a topic analysis of what's hot and what's not on the Subreddit—which is what we aim to find out here. This notebook is still a WIP. Note that down_votes is always zero. Boo. Here are the bylines of the ten most popular stories of all time. Is there even a perceptible difference in the amount of attention given to different topics on r/worldnews? Of course! The extreme outliers, like the terabytes story, are simply due to a small number of observations, as shown below—one "rare event" dominates the mean. We can control for this later on my specifying that our words of interest have to appear at least some number n times. For now let's tokenize our words (using the nltk word_tokenize built-in) and remove a bunch of redundancies—digits, punctuation characters, concatenations—from the result. Here are the most common words in r/worldnews titles: To increase the accuracy of any models that we build let's do one more thing, let's stem our words: mapping "says" and "saying" and "said" all to "say", for example, because they are all really the same one word in different forms. We'll use the nltk built-in PorterStemmer for this. Another effect that we have to control for is the growth of the r/worldnews subreddit over time. What does this look like? In the plot above green is the median score, while blue is the average. White is a seven-day rolling mean for the average. What do we see? We see that the median upvote score of a story on r/worldnews has barely budged over the entire history of the subreddit: it went up from 1.5 or so 6, true, but the difference is peanuts. On the other hand the mean score, influenced heavily by extremely popular stories, has gone through the roof. This fits the way in which a subreddit behaves. A certain small number of users, sometimes called "tastemakers" in the literature, explore the "incoming stories" feed (or whatever it is called) and upvote what they like the most. These stories then get a foothold on the front of the subreddit, where they get massively upvoted by less involved subreddit passerby, and then perhaps even on the front page of Reddit itself, where perhaps the largest hivemind in the Internet are free to upvote it. The result of this structure is that while most stories which get submitted wallow on the bottom, a select few shoot way, way up to the top, with not much in the middle. Examining a typical recent day in the upvote history of the subreddit corroborates this story: We need to normalize our upvote data somehow; if we don't anything we try to do with it will be heavily dependent upon the recency of the story. One option is to use what we were already using: a rolling mean. A more aggressive rolling mean might work well, but it has the tradeoff that we lose the stories that occurred right at the beginning of our history, as we can't ask for "an average over the last two months" for stories within the first two months of history, for example. Another option is building a model fitted to the daily average. This would also be helpful for extrapolating forward, and is certainly a worthy thing to try to build. However that will likely oversimplify important effects in time series data, like seasonality, which simple linear models can't account for. Thus the last and most complex possible build would be to generate a time-series model based on our data, something like the Holt-Winters time series forecasting algorithm. Maybe I'll try these out in a separate notebook, but these are too complex for us right now. Let's instead take advantage of the sheer size of our dataset and use a 120-day rolling mean, which seems pretty smooth and only cuts off a little bit of data right at the beginning of our history. Notice that, mean-adjusted, our stories don't get to positive performance even at the 75th percentile! In fact, we find that over 85 percent of stories do worse than average for the day that they are posted, an extreme skew which fits the story we were telling earlier of a few popular posts, many under the carpet. Let's take a brief detour to ask what the most popular topics are, at least in terms of the raw number of article submitted. Given that karma is the reward mechanism for "good" submissions, this should be pretty well correlated with the best-performing topics are (which we'll explore separately later on). But what is a topic? In the context of a headline a topic isn't just any word, it's the subject of a sentence. While finding the actual subject of a sentence is hard, we can do pretty good, in the context of this problem, by just looking proper nouns in our titles. For that we'll need the nltk pos_tagger built-in. It's not perfect, as you can see below, but it works decently well. Note that we're examining word stems here: more specifically, the word stems of words treated as nouns in r/worldnews submission titles. So "presid*" could means president OR presidents in the original title, for example. Syria is very very high on the list, but no one beats China. Words like attack and war are up there as well. Here's the same chart, expanded out to 50: This is a good starting point from which to explore individual "kinds" of things. For instance, let's look at the representation of various countries in this data. For that we'll use a dictionary of countries provided here. Here are the top fifty countries mentioned on r/worldnews: An important limitation of this analysis is that since we have tagged only individual words, countries whose names consist of more than one word are impossible to find (at least, the way we've done things). I've hacked around this by considering only the last word in the country's name—in this case mapping North Korea and South Korea both to just Korea, for example—but it is, of course, a bit of a hack. If you're interested in pursuing this analysis further I suggest using gensim to construct phrases out of our words and working from there. Another thing that's easy to do is looking at the top topics by sentiment. To do this we can use the off-the-shelf VADER sentiment analyzer available in nltk. Unfortunately this is also a bit wonky because we are asking it to process word stems, not words, and word stems may not even be valid words! You can fix this pretty easily yourself if you're so inclined by running the sentiment analyzer on all of the titles containing that stem and then taking the mean of the sentiment responses. I'm not too concerned about it though because I just want to get an "impressionistic" understanding of what r/worldnews obsesses over, for which what we already have is enough. We have sentiment and we have countries, can we combine the two? Yes. For example here are the polarity scores for the titles of stories involving China. 