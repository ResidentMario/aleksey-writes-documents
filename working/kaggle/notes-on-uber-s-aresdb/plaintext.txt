Time series aggregates are by far the most common dimensionality for analytics use. Some keywords used that I am not 100% familiar with follow: Inverted index â€” a map of values to document locations. Used in full-text search engines, since it makes lookups on a specific word $O(1)$. AresDB is columnar for time-series query efficiency and storage efficiency. Data is stored in terms of fact tables, which are infinite timestamped append-mainly list, and dimension tables describing formats. A "live store" stores uncompressed and unsorted columnar vectors, partitioned into "live batches" of configured capacity. New batches are created at ingestoon, while old batches are purged after their records are archived. Nullity is stored as a (one byte per field) mask vector. An archival store handles persisting data via fact tables. Archive batches are ID-ed (and organized) with the Unix epoch timestamp for the particular day, e.g. they are daily. This means storing an additional count vector as well as the original value value and null vectors. Clients ingest data via an API that requires POST-ing an upsert batch. The message format used is a custom serialized bunary format (why not use one of any of the existing messaging protocols? Weird). This operation makes note of late arriving facts: facts which update values which are unexpectantly past. This is a data warehouse indexing concern; e.g. if you have ever reset the index you lose the abiliy to naively modify record values to account for late arrivals. Archival is an occassional process which is applied to all data in live memory that is within a certain time range. Note that this introduces an archiving delay into the architecture, e.g. we do not completely clear the in-memory live data structure on archival. Although you can certainly configure things that way, if you'd like. Backfill is performed from a backfill queue by a backfill process that is configurable to be time and/or size thresholded (Uber does both). Backfilling is idempotent: making the same call multiple times will create the same result. This is in contrast to regular upsert workloads, which are non-idempotent. Uses AQL, a non SQL JSON fragment based query language mean to be more easily programmatically editable than SQL. The operations are performed using what Uber describes as a one operator per kernel model. Can't find too much info on this online but basically what you do is: AresDB is a fully in-memory database (besides recovery logs obviously). 