This notebook is a primer on non-core PyTorch library features, with the goal of getting a comprehensive high-level overview of what PyTorch can and cannot help you do (beyond the design and execution of the neural network itself). To make model builds reproducible, you must do three things: This seeds the PyTorch CUDA code. However, PyTorch may use certain CUDA functions which have a non-deterministic operation ordering. If you want full reproducibility, you have to know which functions those are and avoid them. This seeds CuDNN (chip firmware providing higher-level operations than raw CUDA). np.random.seed(0) Continue this notebook by going down the list of things on the page https://pytorch.org/features/. More interesting is attached metadata. It is possible to pass a file containing metadata about a model to the PyTorch save function: Since TorchScript files are regular ZIP archives, extra information gets stored as regular files inside archiveâ€™s extra/ directory. I don't know that this format of metadata distribution wins you much, besides the fact that it is natively supported. You can do this yourself as an internal code standard with a teeny bit more work. Here is the code sample demonstrating single-device XLA usage: 