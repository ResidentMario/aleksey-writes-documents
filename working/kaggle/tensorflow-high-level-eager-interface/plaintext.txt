Note: this notebook is a translated version of https://www.tensorflow.org/get_started/eager. Import Tensorflow and turn on eager execution. Eager execution performs NN tasks right away, instead of waiting for two-step graph initialization and runtime, as in the (notably more awkward) low-level API utilization. Next we create a three-layer Keras model. The last layer, the output layer, has as many nodes as classes in this classification problem. The hidden layers can have as many nodes as you would like, and you can have as many hidden layers as you would like. The input layer is not declared explicitly, but instead configured via the input_shape parameter on the first hidden layer's declaration, which is required. The Dense layer is fully interconnected. In other words, every node in a successor layer relies on every node in the previous layer. Tensors passed between nodes in the hidden layers have a functor applied to them. The Dense layer uses the following functor by default: The input is the input tensor. The kernel is a group of weights shared over the input space (basically feature importance). The dot product of the kernel and the input is a transformed feature vector. The bias is a linear transform applied to the entire input tensor. The activation function is a function that is applied to the result of the rest of the operations right before the whole thing is handed on down to the next neuron in the set. Training a neural network model means optimizing the kernel (the weights) and the bias. To do so, we must define a loss to minimize, and a gradient function to use to "seek out" that loss minimum. In this next code block we define a loss functor. Here's a configured optimizer. Eager execution introduces a gradient tape, or GradientTape. This object is a context manager that "records operations for automatic differentiation". Variables (persistant tensors) are automatically recorded, whilst regular tensors can be recorded using an explicit GradientTape.watch function call. The tape is a space for performing automatic differentiation. Graphs defined within the tape gain a gradient object method that can be used to take the gradient. This gradient can then be given to an optimizer, which will determine, based on the gradient and other factors, how best to tune the model parameters. For example, here is a gradient computation for the function x * x at the value 3: We will define a grad method which, given the model inputs and a loss factory function, returns the gradient applied to that loss function within that input space, using a fresh gradient tape to do it. 