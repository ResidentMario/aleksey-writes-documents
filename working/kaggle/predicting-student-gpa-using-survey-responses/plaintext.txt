This notebook is an experiment to see how successful we can be at predicting GPA using survey responses alone. That is to say, can well can we tell the grade point of a student based on how satisfied they rate themselves with their education in the survey questionaire? Are more satisfied students strongly likely to be good students? I'm curious to see how bad (or surprisingly good) the result would be. The better the result, the more differenciable the survey-takers, and hence, (probably) the better the survey is. Personally I am not confident that this will be true-ish as I think most users basically all answer the same way, regardless of how poor things really are for them. To start with, here are our GPAs. They're fairly, but surprisingly not totally, correlated. H.S.C. looks easier to model, so let's stick to that one. Next we do a ton of feature selection. In particular, we throw out the fields that give GPA-ish information. We want to stick to the survey questions: things like how satisfied are you with X, how good is Y, etcetera. Interestingly enough, irregular students have a lower GPA on average. But it's not that significant an effect, due to the small sample size. We'll use ridge regression, because why not? And we get... ...it's not very good! You can tell from this plot that the classifier mostly failed right away because of how densely clustered the result is around 4. This indicates that the model did not that much better at capturing the shape of the data than just settling on the average of the distribution at large. Obviously we want a classifier that does better than that, but this one mostly doesn't! Another view: Fit statistics. Student GPA is not correlated with the level of satisfication that they indicate on survey data. 