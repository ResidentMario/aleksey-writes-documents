Full-sized batches running on GPU with a custom scoring function, RMSPE, which is what was used in the competition. That's a big RMSPE value, +/- 75% of the target value, the best models submitted to the competition achieved a RMSPE of +/- 10%. At least, that's my interpretation...I'm not actually sure, because the competition metrics state "0.1", which seems impossibly high accuracy if it is actually accuracy to 0.1%. E.g. that's being one off from estimating a value of 1000, which I don't believe. I will continue to fiddle with this model. First, let's get it to converge. Then, let's introduce cyclic learning. 