Instead of learning the weights directly, the network is redirected to learn a function of the $w$ vector that looks like so: $$w = \frac{g}{||v||}v$$ Where $||v||$ is the unit norm of $v$ and $g$ is a scalar value. $v$ has the same dimensionality of $w$. Both $v$ and $g$ are learned parameters; in effect under this scheme we are learning one additional parameter as part of the weight, a scaling factor $g$.  Spectal normalization creates the constraint (typically in the discriminator module) that the weights matrix exhibits Lipschitz continuity. This property essentially means that the gradient created by the weights matrix exhibits a certain (constant-controllabe!) level of functional smoothness in all directions. The Wikipedia article has a great visualization of what this looks like, using a double cone on a linear function here. This is achieved by normalizing the weights matrix by the matrix's largest eigenvalue. This value is equivalently the spectral norm (the norm with $p=\infty$; see the notebook "L1 versus L2 norms") of the matrix. See this StatsOverflow Q&A for a bit of explanation. 