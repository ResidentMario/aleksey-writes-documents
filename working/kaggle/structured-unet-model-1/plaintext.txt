This is a relatively simple model submission using the same UNet neural network provided in the "UNet with Depth" kernel. The cells that follow define a sequence of image transformations, most of them taken from an excellent post by Heng. All of our transforms follow the standard sklearn transform pattern. Now that we've defined all this machinery, here we apply it. Now we define the neural network. This is a UNet, as noted previous taken from the "UNet with depth" kernel. That was our model description. Now we need to train the model. Note the collection of keras callbacks we use here to modify the learning behavior: Note that all of these callbacks were inherited from the prior kernel, "UNet with depth". Let's take a quick look at what we got. In the following plot the first element is the raw image, the second element is the ground truth, the third element is the prediction, and the fourth image is the difference between the prediction and the ground truth: green where we added false positives, and red where we added false negatives. I'm using this as a quick sense check the the model is indeed learning useful things about the dataset. Notice here that we're using np.round on the output. By default, the model will output what is roughly interpretable as confidence scores for each pixel in the image, but the competition submission format expects us to provide prediction classes, not prediction confidences. So we round our values to 0 or 1. Let's go ahead and predict the test values that we'll submit. I clean up a bunch of no longer necessary leftover variables to free up RAM. The training data is reasonably large, and if we don't get rid of a few things it may overflow RAM and crash the kernel. The competition expects us to submit results in a run-length encoded format, but we generate our results as matrices of prediction values. To make the output legal for submission to the competition, we have to perform this encoding. The follow algorithm, RLenc, came from the early kernel "How to geophysics kernel". Given an input image matrix, it outputs the encoded string. Finally we'll build the submission and save it to disc. Note that the model expects input in the form of, and predicts outputs shaped like, arrays whose dimensions are multiples of 32. But the competition images are 100 by 100. So we have to scale the images up, score them with the model, then scale them back down (using our ScaleBoth transform from earlier). Here's what our output looks like. Note the use of a run-length encoded string in the output column. To submit this model prediction to the competition, navigate to the Data tab on the kernel (after you've finished running it) and click on the "Submit to competition" button. This is a very unoptimized kernel. It implements and runs a handful of useful transformations, uses a pretty standard model, and then immediately submits the result. I don't claim this is a good model, but I do think it's a decent starting point. =) We can improve all three of the steps: preprocessing, modeling, and postprocessing. Here are some ideas (this is not original research; these were taken mostly from the forums): Postprocessing Good luck! 