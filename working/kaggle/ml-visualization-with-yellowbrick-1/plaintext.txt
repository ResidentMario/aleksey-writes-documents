This is the first notebook in short series in which I explore the yellowbrick library. The cute module name comes from the famous "follow the yellow brick road" line in The Wizard of Oz. Data visualization is an integral part of the machine learning process during all of the preprocessing, exploration, and model-building stages. yellowbrick is the only machine learning -focused visualization library that I'm aware of, which probably means it's the only one with any real traction. This is surprising of course; it turns out that a lot of ML engineers are happy to rely on hacky matplotlib recipes they once spent a lot of time working out! An ML process -focused data viz library sounds like a honking good idea. Let's see how well this library executes on the promise. Note that this is all based on the official documentation here. For this notebook I'll use the Kepler space observations dataset. This plots a simple bar chart in one dimension ranking the data according to some statistic, hence the name. The name is a misnomer for now, however, as though the method provides an algorithm field the only algorithm that works at the moment is the Shapiro-Wilk test, a statistical test (with a confidence score on the $[0, 1]$ scale) of whether or not the given feature is normally distributed. The Shapiro-Wilk is a useful tool for visualizations because it lets you test normality of variables using a single test statistic, e.g. without relying on a huge list of plots. Much less cumbersome. For more on the test, the Wikipedia article is informative. If you're not familiar with hypothesis testing, I wrote a notebook on this subject which might be worth reading. Here's what you get: This is the output of a statistical test, but since we're not making any decisions based on it there's no need to choose a specific level of significance ($p$ value). You can see that ra and dec are very normally distributed ($p = 0.05$). The rest of the values are not normally distributed. Note that those flag values, which may only be 0 or 1, are scoring between 0.5 and 0.6 according to this metric! Semi-interesting. It's dissappointing that the Shapiro is the only algorithm you can currently output to this plot. We need more testing options, and also the option to provide the test statistic yourself! Rank2D implements a seaborn heatmap (reference to that here) with some good defaults. Where Rank1D relies on one-dimensional metrics, Rank2D provides a facility for two-dimensional metrics, e.g. things like correlation, covariance, and so on. Again the API is super-limiting, with only covariance and pearson options (see this notebook for a background on these metrics). There are lots more useful metrics that could be implemented; Spearmen's correlation, for example (I discuss that here). This API needs expanding! Nevertheless, for that particular use case this is a lot more convenient than specifying a heatmap manually. Parallel coordinates are a lovely plot type. Given an input of normalized data, parallel coordinate plotting will lay out the feature space and plot out where each point falls on it. We see a few different interesting effects here. For one there's a long push of outliers of observation durations, all of which correspond with observations that were NOT CONFIRMED. That seems significant. Also, we can see that the probability that Kepler assigns to planets that get CONFIRMED (koi_score) is quite high, but not always 100 percent (in interpreting this fact, recall that this feature is scaled to fall between $[-1, 1]$). Parallel coordinates plots are overall a very useful chart type, though not one without weaknesses. It's great to have a neat interface to it like this. But it's worth pointing out that this plot type is just reimplementing a pandas.plotting built-in (see here). Meanwhile another related albeit less interpretable pandas.plotting built-in, the Andrews curve, is missing. For a bit more on parallel coordinates I have a brief section on it in the Python Data Visualization Learn Track (here). RadViz is another re-packaged pandas.plotting built-in. This visualization type lays out the features of the dataset in a circle, then plots the position of each point under consideration in that circle by pushing it towards the variables it loads heavily in. This is also sometimes called the "spring layout". It can be quite useful for visualizing distinguishabile attributes between class clusters; I find it to be a very understandable way of explaining which $n$ variables a particular class loads heavily on, when $n$ is greater than 2. This chart only tells us that planets that got confirmed loaded heavily in the pre-disposition, which is something we probably already figured. PCA, or Principal Components Analysis, is a dimensionality reduction technique which lets us drop the number of variables under consideration to some user-specified subset thereof. PCA works by finding the "natural directions" in a dataset, e.g. calculating new synthetic feature observations along the dataset axes that cover the most variance in the dataset, and hence, are the most "interesting". Note that PCA is an unsupervised algorithm that does not consider labels we assign to the data (e.g. classes). I wrote a lengthy primer on PCA that you can read here if you're not already familiar with it. PCA is a great technique for EDA because by examing the axes that get chosen by the algorithm we're better able to understand what combinations of variables have the highest variance and "coverage" in the dataset. What does yellowbrick do with this? These 2-d and 3-d scatter plots are good for probing how difficult a classification or regression problem will be. Here we see that the observations naturally cluster into two groups, but that the relative distribution of the class of interest within that group doesn't differ between them. If we move on to examining what it is about the data that is creating these quite separable structures, we will make great gains in understanding what the underlying data describes. There is more that can be done with PCA than this, though. This library needs more options! Feature importance is the relative usefulness of a given feature for performing a classification or regression task. The FeatureImportances chart type takes advantage of the exploratory power of decision tree algorithms, which provide a feature_importance_ result once fitted, to plot this information directly. If you're not familiar with decision trees you can read up on them here. This plot type is a great use of decision trees for EDA. Again though, you can go a bit further by training and fiddling with the decision tree yourself. These are all of the feature exploration features included in yellowbrick. That concludes this notebook! For the next section click here: https://www.kaggle.com/residentmario/ml-visualization-with-yellowbrick-2/ 