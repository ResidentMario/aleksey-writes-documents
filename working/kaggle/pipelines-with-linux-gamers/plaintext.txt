In the previous notebook I introduced the concepts of cross validation and hyperparameter search (if you don't know what those are, or need a refresher, start there). I implemented grid search by hand in a separate notebook, but the technique that we implemented in that notebook are built into scikit-learn as the GridSearchCV (of course!). In this notebook we'll look at how this work can be managed by a scikit-learn pipeline. You can declare a pipeline directly as an object, using the Pipeline constructor, or use the make_pipeline convenience function (which we will use). Recall that for our model in the previous notebook we used polynomial regression and performed hyperparameter search over the degrees of our variables. Organizing that into a simple pipeline is easy. You can get the steps you are using with steps or named_steps utility methods. Setting a parameter is weird, though. You have to take the name of the step, add a __, and then specify what you want to mutate that step's parameter to. We can use fit and predict on the pipeline to get a result, as usual. A pipeline technically needs to consist of a string of n transformations (classes that implement a callable transform method) and then a single model at the end (implementing fit and predict). That means that it is very easy to write our own functions for insertion in a pipeline, if we are so inclined. Running a grid search occurs outside of the pipeline, on the pipeline. Getting the result is as simple as throwing the pipe into GridSearchCV. The resulting model is stored in the estimator parameter. For simple models like this one the benefit of using a pipeline is relatively small. However, for increasingly complex models, the organizational "struts" that the pipeline provides are increasingly useful. The scikit-learn documentation lists these three benefits to using pipelines: Convenience and encapsulation You only have to call fit and predict once on your data to fit a whole sequence of estimators. Joint parameter selection You can grid search over parameters of all estimators in the pipeline at once. Safety Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors. Convenience and encapsulation is an obvious one. The purported benefit of joint parameter selection is interesting; using a pipeline unlocks the ability to do more complicated grid searches, like, for example, mixing and matching what kinds of transforms we apply to the dataset before running (and potentially searching through) the model. The point on safety is hardest to explain. Basically, using a pipeline helps defend against a difficult-to-escape form of model leakage known as "knowledge leakage". This warrents another notebook: for more on that, read this notebook. It's also worth briefly mentioning the FeatureUnion class. This class provides a way of combining transforms without having to place an estimator at the end (e.g. it's a pipeline[:-1]). 