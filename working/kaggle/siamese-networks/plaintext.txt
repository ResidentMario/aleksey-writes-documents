Siamese networks is a neural network archetype that learns to determine whether two examples are the same or different. This architecture is the most effective way of extending the expertise and learning capacity of neural networks to small datasets. True to its name, it does this by training on images in pairs, instead of training on them one-at-a-time. For an example of an application of a Siamese network, consider the Kaggle competition "Painter by the Numbers". The objective in this competition was to classify paintings by painter, and to determine what elements in an unknown set of paintings is attributable to the artist and which ones are forgeries. A classical approach to this problem would be to train a CNN with a categorical output layer, but because the training set was small, and the objective is explicitly pairwise, Siamese networks are very well-suited. This notebook is based on the following pair of blog posts: "One Shot Learning with Siamese Networks in PyTorch" and "Facial Similarity with Siamese Networks in PyTorch". Siamese networks have the following architecture:  They consist of two submodels whose outputs are evaluated using contrastive loss. Contrastive loss measures how well the network is able to distinguish between two different pairs of images, by measuring a function of the Euclidean distance (you can also use some other norm, if you'd like) between the outputs of the two component networks. Contrastive loss in this way encourages the networks to build output vectors that compose a space where each class of output composes a cluster that is as far away from the other class clusters as possible. The architecture is known as a Siamese network because the left and right models are exactly the same: e.g. they are not just structural clones of one another, but the exact same model, down to the weights. The following example Siamese network, implemented in PyTorch, is courtesy of the Part 2 article. The implementation is presented here with comments. This code is not run-able because the data is elsewhereâ€”in the project GitHub repo. For a Keras version of this same concept, see the following article: https://sorenbouma.github.io/blog/oneshot/. 