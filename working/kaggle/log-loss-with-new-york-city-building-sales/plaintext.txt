Note: this notebook is an addendum to the Classification Metrics notebook. Log-loss is a model performace metric which is often used within competition contexts (it is, for example, a very popular metric in Kaggle competitions). Unlike the rest of the model metrics covered in the notebook above, it involves a reasonably complicated mathematical formula. To define log-loss mathematically, start by defining $p_{ij}$ as the probability the model will assign label $j$ to record $i$; $N$ as the number of records; $M$ as the number of class labels, and $y_{ij}$ as an indicator variable which is 1 if record $i$ is assigned class $j$ by the model, and 0 otherwise. Then log-loss is "simply": In other words, log-loss is a logarithmic transform of the sum of the probabilities the model assigns to the records it misclassifies. This excellent blog post, the material inspiration for this notebook, has the following illustration of the effect this has:  Log-loss exponentially penalises misclassifications that are highly confident. In the log-loss world, a 0 observation which is predicted with 80% confidence to be a 1 observation (and classified thusly) is penalized much more heavily than a miscalled observation made with 55% confidence. So, in cases in which the result is wrong, it is much better for a model to be somewhat wrong than extremely wrong. In this way it's a bit like linear regression, in that extreme outliers will give exponentially bad log-loss results. Hence the log-loss metric rewards "honest" models and rewards models that find ways to deal with outliers. This makes it an intuitively good metric to use for cases where getting reasonable classifications for all records, not just some or the bulk of them, is important (and this need occurs in many real-world contexts). What is a good log-loss? A log-loss of around 0.693 is random performace, and anything below that is "better than random". For some difficult applications, a log-loss as high as 0.4 is good. But this depends a lot on the domain! Here's an implementation on a prediction of NYC building sales: how well can be predict whether or not a unit will sell for 1+ million dollars, based on the number of units alone? That's some really bad performance. :D 