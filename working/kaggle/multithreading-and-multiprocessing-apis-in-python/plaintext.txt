This section based on the following Real Python tutorial: https://realpython.com/intro-to-python-threading/. The simplest way to manage concurrency in threads is to start a list of threads and then join them sequentially. This is fine, but there is a built-in that does this for you: concurrent.futures.ThreadPoolExecutor. That looks thus: There is some confusing aspects of how this API works and is run. In particular, errors in the function signature of thread_function will be swallowed without an error being raised. In this code sample the pipeline object represents all of the shared state: a queue, effectively, with a SENTINEL value representing end-of-queue. A thread having to wait for a lock allows a context switch to another thread, and this is used to the benefit of this program (which has two threads, a producer and a consumer) by having one thread execute a function which acquires the lock it needs, do some work, release the lock needed by its compatriot, and exit. The now-exited function never released the lock that the next iteration of that function needs to execute, so the next iteration of the function blocks, yielding executing to its companion. The companion function does some work and reverses the locks, blocks itself, releases execution to the previous function, which is now unblocked, and so on and so forth until the entire queue is consumed. This system of dueling locks is an academically interesting example. In real cases you would use a queue, which is the next example. Queue is a thread-safe object which may freely be shared between threads (as here; enqueue and dequeue are locked operations, presumably?). The main thing introduced in this example which is new to me is the multithreading Event API, which allows you to share a once-only-incremented boolean flag between threads. This is used here to shut down the producer operations in the main thread, and to prevent the consumer from stopping too soon (if it outstrips the producer due to scheduling and empties out the queue). This section based on the following Real Python tutorial: https://realpython.com/python-concurrency/. In multithreading the main thread creates all of the shared state that the child threads work with. In multiprocessing this connection is less direct; processes do not share memory (at least, not inside of the Python process) and must incur IPC costs (e.g. serializing and deserializing objects, and transfering them to one another over sockets) in order to communicate with one another. This, plus the heavyweight nature of processes (versus more lightweight threads), is the chief reason disadvantage of multiprocessing. The chief advantage of multiprocessing is freedom from the GIL (so true parallelization, as opposed to mere concurrency, is possible). In the multiprocessing API the Thread analogue is Process. A trivial example of a multiprocess program is: Here's an example of a slightly less trivial multiprocess program: At the present time: There are two high-level primatives for IPC: the mp.Queue, and the mp.Pipe. The latter is essentially a two-sided queue, and is multiprocess-safe so long as processes communicating over a pipe do so by working on different ends of it. This prints: The most important point is that forking a process immediately kills all threads except for the one doing the forking. Because this is done at the OS level, other threads may be in inconsistent states at the time at which this occurs. If they are holding a global lock, that lock will not be released before the thread exits. Any child that attempts to access the resource protected by that lock will deadlock. In Python's case, the following resources can cause this problem: The article cites the following generic example: An application spawns a thread X. This thread is allocating a memory buffer. The memory allocator locks a global mutex.While thread X is allocating a memory buffer and also has a lock on the global mutex, the application's main thread forks. The child process also allocates some memory. But the memory allocation mutex is locked, and X is gone, so it will never be unlocked. The child process deadlocks forever. In the High Sierra release Apple started to enforce a rule that processes may not initialize a new Objective-C API inside of a forked process. This has raised many errors that users were making with said locks from silent to loud, which is good. 