Keras is a high-level API specification for building machine learning models. It's independent of any one implementation. The primary implementation of the Keras API is the keras library, which allows you to define and use NNs based on any of three supported backends. Tensorflow also has its own implementation of the keras API in the form of its tf.keras module, which seems to be the high-level API of choice within the library (see comments near the bottom of this previous notebook). The Keras model definition API is split across two different class-based starters. The Sequential base is simpler, and organized in terms of sequential layers. More complicated graphs may be constructed using the functional Model, which allows non-sequential layer and element construction. A basic sequential model definition is: This is very similar to what the Tensorflow tf.layers API does. Again you have to specify an input_dim to the first layer, but not to any of those that come after. After defining a model there is a compilation step, at which point the model is "built" against the backend using the given optimizer and loss function. Once compiled, fit, evaluate, and predict methods are available on the model for utilization. A complete example: The Keras functional API is similar to the Tensorflow low-level API. Each node that we attach returns an output tensor. We can keep attaching nodes to tensors as we go along. Models can be attached tensorwise all at once, forming subgraphs within the overall computational graph. For instance here is the beginning of a multi-output model defined in the Keras functional API tutorial: The keras.layers.concatenate layer is used to merge output from different precursor nodes together. In this code example it is used to merge the LSTM output with the auxillary data input. The model instantiation needs to know where the inputs and outputs are. There's more to this that I'm just glossing over for now. 