Estimators are Tensorflow's high-level API, comparable to sklearn in look and feel. They sit on top of the library's lower layers-based API (demonstrated here), which itself sits on top of the lowest level raw computational graph API (discussion here). Estimators handle sessionization (building and tearing down the Session) and graph construction (likewise with the Graph) for you. They are designed to pipeline easily and to be extensible and buildable. Using estimators comes down to four steps. First, define an input function, whose job will be to return a tuple whose first item is a feature-tensor key value pair and whose second item is a tensor of labels. Next, define the feature types, using e.g. tf.feature_column.numeric_column. Next instantiate the estimator. Finally, run the estimator on the data. The one additional step over sklearn is the need to pass the features to objects ahead of computation. This is because it needs you to associate type information with your data. You can use the Tensorflow datasets API to handle pre-processing. But you can also use any other data processing tool to do the job...like, say, pandas. The three functions on an Estimator are train, evaluate, and predict. train-predict is equivalent to fit-predict in sklearn. evaluate returns some information on classifier performance, though you can obviously also evaluate outside of the loop. 