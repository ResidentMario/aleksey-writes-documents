<!doctype html><html lang="en"><head><script>!function(n,e){var t,o,i,c=[],f={passive:!0,capture:!0},r=new Date,a="pointerup",u="pointercancel";function p(n,c){t||(t=c,o=n,i=new Date,w(e),s())}function s(){o>=0&&o<i-r&&(c.forEach((function(n){n(o,t)})),c=[])}function l(t){if(t.cancelable){var o=(t.timeStamp>1e12?new Date:performance.now())-t.timeStamp;"pointerdown"==t.type?function(t,o){function i(){p(t,o),r()}function c(){r()}function r(){e(a,i,f),e(u,c,f)}n(a,i,f),n(u,c,f)}(o,t):p(o,t)}}function w(n){["click","mousedown","keydown","touchstart","pointerdown"].forEach((function(e){n(e,l,f)}))}w(n),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){c.push(n),s()}}(addEventListener,removeEventListener)</script><script defer src="https://cdn.optimizely.com/js/16180790160.js"></script><title data-rh="true">Boost your CNN image classifier performance with progressive resizing in Keras | by Aleksey Bilogur | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2019-04-02T00:12:53.825Z"/><meta data-rh="true" name="title" content="Boost your CNN image classifier performance with progressive resizing in Keras | by Aleksey Bilogur | Towards Data Science"/><meta data-rh="true" property="og:title" content="Boost your CNN image classifier performance with progressive resizing in Keras"/><meta data-rh="true" property="twitter:title" content="Boost your CNN image classifier performance with progressive resizing in Keras"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/a7d96da06e20"/><meta data-rh="true" property="al:android:url" content="medium://p/a7d96da06e20"/><meta data-rh="true" property="al:ios:url" content="medium://p/a7d96da06e20"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of neural network which build progressively higher level features out…"/><meta data-rh="true" property="og:description" content="If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of…"/><meta data-rh="true" property="twitter:description" content="If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of…"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*TnSDLVixRZfGZksBLT7kMA.jpeg"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*TnSDLVixRZfGZksBLT7kMA.jpeg"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" property="article:author" content="https://medium.com/@aleksey.bilogur"/><meta data-rh="true" name="author" content="Aleksey Bilogur"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" name="twitter:label1" value="Reading time"/><meta data-rh="true" name="twitter:data1" value="8 min read"/><meta data-rh="true" name="parsely-post-id" content="a7d96da06e20"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="author" href="https://medium.com/@aleksey.bilogur"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/a7d96da06e20"/><link data-rh="true" rel="icon" href="https://miro.medium.com/fit/c/256/256/1*ChFMdf--f5jbm-AYv6VdYA@2x.png"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*TnSDLVixRZfGZksBLT7kMA.jpeg"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fboost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20","dateCreated":"2019-04-02T00:12:53.825Z","datePublished":"2019-04-02T00:12:53.825Z","dateModified":"2020-10-19T23:12:07.889Z","headline":"Boost your CNN image classifier performance with progressive resizing in Keras","name":"Boost your CNN image classifier performance with progressive resizing in Keras","description":"If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of neural network which build progressively higher level features out…","identifier":"a7d96da06e20","keywords":["Lite:true","Tag:Machine Learning","Tag:Keras","Tag:Cnn","Tag:Optimization","Tag:Fastai","Topic:Machine Learning","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:4"],"author":{"@type":"Person","name":"Aleksey Bilogur","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@aleksey.bilogur"},"creator":["Aleksey Bilogur"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fboost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20"}</script><script data-rh="true" >(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="https://cdn.optimizely.com/js/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="545" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-moz-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-webkit-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-moz-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-webkit-keyframes k3{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k3{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k3{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:35px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{margin-bottom:36px}.v{width:100%}.w{overflow-x:scroll}.x{white-space:nowrap}.y{scrollbar-width:none}.z{-ms-overflow-style:none}.ab::-webkit-scrollbar{display:none}.ac{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.ae{min-height:184px}.ah{flex-direction:column}.ai{background-color:#355876}.aj{display:none}.al{border-bottom:none}.am{position:relative}.an{z-index:500}.at{max-width:1192px}.au{min-width:0}.av{height:62px}.aw{flex-direction:row}.ax{flex:1 0 auto}.ay{visibility:hidden}.az{margin-left:0px}.ba{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bb{font-size:14px}.bc{line-height:20px}.bd{color:rgba(197, 210, 225, 1)}.be{color:rgba(53, 88, 118, 1)}.bf{fill:rgba(53, 88, 118, 1)}.bg{font-size:inherit}.bh{border:inherit}.bi{font-family:inherit}.bj{letter-spacing:inherit}.bk{font-weight:inherit}.bl{padding:0}.bm{margin:0}.bn:hover{cursor:pointer}.bo:hover{color:rgba(99, 127, 153, 1)}.bp:hover{fill:rgba(99, 127, 153, 1)}.bq:disabled{cursor:default}.br:disabled{color:rgba(26, 137, 23, 0.3)}.bs:disabled{fill:rgba(26, 137, 23, 0.3)}.bt{height:25px}.bu{fill:rgba(233, 241, 250, 1)}.bv{min-height:115px}.bw{justify-content:space-between}.cc{align-items:flex-start}.cd{margin-bottom:0px}.ce{margin-top:-32px}.cf{flex-wrap:wrap}.ci{margin-top:32px}.cj{margin-right:24px}.cl{width:112px}.cm{flex:0 0 auto}.cn{justify-self:flex-end}.co{margin-right:12px}.cp{height:32px}.cq{overflow:visible}.cr{border-radius:1000px}.cs{background-color:rgba(53, 88, 118, 0.8)}.ct{fill:rgba(197, 210, 225, 1)}.cu:hover{fill:rgba(251, 255, 255, 1)}.cv{color:inherit}.cw{fill:rgba(117, 117, 117, 1)}.cx{outline:none}.cy{padding:4px}.cz{margin-left:8px}.da{margin-right:10px}.db{margin-top:16px}.dc{margin-bottom:16px}.dd{display:inherit}.de{max-width:210px}.df{text-overflow:ellipsis}.dg{overflow:hidden}.dh{display:inline-block}.di{border:none}.dj{font:inherit}.dk{font-size:16px}.dl{opacity:0}.dm{background-color:transparent}.dn{color:rgba(233, 241, 250, 1)}.do::placeholder{color:rgba(197, 210, 225, 1)}.dp{padding:0px}.dq{width:0px}.dr{transition:width 140ms ease-in, padding 140ms ease-in}.ds{fill:inherit}.dt:hover{color:rgba(242, 248, 253, 1)}.du:hover{fill:rgba(242, 248, 253, 1)}.dv:disabled{color:rgba(197, 210, 225, 1)}.dw:disabled{fill:rgba(197, 210, 225, 1)}.dx{padding:4px 12px 6px}.dy{background:0}.dz{border-color:rgba(215, 226, 238, 1)}.ea:hover{color:rgba(251, 255, 255, 1)}.eb:hover{border-color:rgba(251, 255, 255, 1)}.ec:disabled{cursor:inherit}.ed:disabled{opacity:0.3}.ee:disabled:hover{color:rgba(233, 241, 250, 1)}.ef:disabled:hover{fill:rgba(233, 241, 250, 1)}.eg:disabled:hover{border-color:rgba(215, 226, 238, 1)}.eh{border-radius:4px}.ei{border-width:1px}.ej{border-style:solid}.ek{box-sizing:border-box}.el{text-decoration:none}.em{fill:rgba(251, 255, 255, 1)}.en{padding-top:1px}.eo{height:70px}.eq{line-height:24px}.er:before{margin-bottom:-10px}.es:before{content:""}.et:before{display:table}.eu:before{border-collapse:collapse}.ev:after{margin-top:-6px}.ew:after{content:""}.ex:after{display:table}.ey:after{border-collapse:collapse}.ez{color:rgba(117, 117, 117, 1)}.fa{margin-right:32px}.fb{margin-bottom:-16px}.fc{margin-top:-14px}.fd{color:rgba(255, 255, 255, 1)}.fe{padding:7px 16px 9px}.ff{fill:rgba(255, 255, 255, 1)}.fg{background:rgba(102, 138, 170, 1)}.fh{border-color:rgba(102, 138, 170, 1)}.fi:hover{background:rgba(90, 118, 144, 1)}.fj:hover{border-color:rgba(90, 118, 144, 1)}.fk:disabled:hover{background:rgba(102, 138, 170, 1)}.fl:disabled:hover{border-color:rgba(102, 138, 170, 1)}.fm{display:inline-flex}.fn:hover{color:rgba(25, 25, 25, 1)}.fo:hover{fill:rgba(25, 25, 25, 1)}.fp:disabled{color:rgba(117, 117, 117, 1)}.fq:disabled{fill:rgba(117, 117, 117, 1)}.fr{margin-left:12px}.fs{margin:0 12px}.ft{position:absolute}.fu{right:24px}.fv{margin:0px}.fw{border:0px}.fx{cursor:pointer}.fy{stroke:rgba(117, 117, 117, 1)}.gb{border-top:none}.gc{left:0}.gd{position:fixed}.ge{right:0}.gf{top:0}.gh{margin-top:0px}.gi{height:60px}.gl{color:rgba(102, 138, 170, 1)}.gm{fill:rgba(102, 138, 170, 1)}.gn:hover{color:rgba(90, 118, 144, 1)}.go:hover{fill:rgba(90, 118, 144, 1)}.gp{padding-left:24px}.gq{padding-right:24px}.gr{margin-left:auto}.gs{margin-right:auto}.gt{max-width:728px}.gu{top:calc(100vh + 100px)}.gv{bottom:calc(100vh + 100px)}.gw{width:10px}.gx{pointer-events:none}.gy{word-break:break-word}.gz{word-wrap:break-word}.ha:after{display:block}.hb:after{clear:both}.hc{max-width:680px}.hd{max-width:4950px}.hj{clear:both}.hl{cursor:zoom-in}.hm{z-index:auto}.hn:focus{transform:scale(1.01)}.ho{transition:opacity 100ms 400ms}.hp{height:100%}.hq{will-change:transform}.hr{transform:translateZ(0)}.hs{margin:auto}.ht{background-color:rgba(242, 242, 242, 1)}.hu{padding-bottom:40.4040404040404%}.hv{height:0}.hw{filter:blur(20px)}.hx{transform:scale(1.1)}.hy{visibility:visible}.hz{margin-top:10px}.ia{text-align:center}.id{text-decoration:underline}.ie{line-height:1.23}.if{letter-spacing:0}.ig{font-style:normal}.ih{font-weight:700}.jc{margin-bottom:-0.27em}.jd{color:rgba(41, 41, 41, 1)}.jh{border-radius:50%}.ji{height:28px}.jj{width:28px}.jk{margin:0 4px}.jl{margin:0 7px}.jm{align-items:flex-end}.jv{padding-right:6px}.jw{margin-right:8px}.jx{fill:rgba(61, 61, 61, 1)}.jy{margin-right:-6px}.jz:hover{fill:rgba(8, 8, 8, 1)}.ka:focus{fill:rgba(8, 8, 8, 1)}.kb{line-height:1.58}.kc{letter-spacing:-0.004em}.kd{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.kt{margin-top:24px}.ku{margin-bottom:-0.46em}.la{padding:2px 4px}.lb{font-size:75%}.lc> strong{font-family:inherit}.ld{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.le{box-shadow:inset 3px 0 0 0 rgba(41, 41, 41, 1)}.lf{padding-left:23px}.lg{margin-left:-20px}.lh{font-style:italic}.li{line-height:1.12}.lj{letter-spacing:-0.022em}.lk{font-weight:500}.md{margin-bottom:-0.28em}.mj{max-width:1166px}.mp{padding-bottom:96.22641509433961%}.mq{max-width:735px}.mr{padding-bottom:78.2312925170068%}.ms{max-width:759px}.mt{padding-bottom:65.08563899868247%}.mu{padding-bottom:NaN%}.mv{max-width:800px}.mw{padding-bottom:75%}.mx{list-style-type:decimal}.my{margin-left:30px}.mz{padding-left:0px}.nf{list-style-type:disc}.ng{will-change:opacity}.nh{width:188px}.ni{left:50%}.nj{transform:translateX(406px)}.nk{top:calc(65px + 54px + 14px)}.nn{top:159px}.np{width:131px}.nq{padding-bottom:28px}.nr{border-bottom:1px solid rgba(230, 230, 230, 1)}.ns{font-size:12px}.nt{line-height:16px}.nu{letter-spacing:0.083em}.nv{text-transform:uppercase}.nw{padding-bottom:5px}.nx{padding-top:5px}.ny{padding-top:2px}.nz{padding-top:14px}.oa{padding-top:28px}.ob{margin-bottom:19px}.oc{margin-left:-3px}.oi{outline:0}.oj{border:0}.ok{user-select:none}.ol{cursor:not-allowed}.om> svg{pointer-events:none}.on:active{border-style:none}.oo{-webkit-user-select:none}.op:focus{fill:rgba(41, 41, 41, 1)}.oq:hover{fill:rgba(41, 41, 41, 1)}.or{opacity:0.25}.oz button{text-align:left}.pa{opacity:0.4}.pb{padding-right:9px}.pk{margin-top:40px}.pl{border-top:3px solid rgba(102, 138, 170, 1)}.pm{padding:32px 32px 26px 32px}.pn{margin-top:8px}.po{margin-bottom:25px}.pp{background-color:rgba(250, 250, 250, 1)}.pr{padding-bottom:0px}.qc{padding-top:4px}.qd{font-size:13px}.qe{padding-bottom:10px}.qf{padding-top:8px}.qq{margin:10px 20px 10px 0}.qs{padding:7px 20px 9px}.qt{margin:10px 0 10px 0}.qu{max-width:380px}.qv{padding-bottom:25px}.qw{margin-top:25px}.qx{max-width:155px}.rb{top:1px}.rp{margin-left:-1px}.rq{margin-left:-4px}.ry{padding-right:8px}.rz{padding-bottom:40px}.sa{list-style-type:none}.sb{margin-bottom:8px}.sc{line-height:22px}.sd{border-radius:3px}.se{padding:5px 10px}.sf{background:rgba(242, 242, 242, 1)}.si{padding-bottom:4px}.sj{padding-top:32px}.su{display:-webkit-box}.sv{-webkit-line-clamp:1}.sw{-webkit-box-orient:vertical}.sy{padding-right:168px}.sz{padding-top:25px}.tf{max-width:100%}.tg{margin-bottom:96px}.th{background:rgba(255, 255, 255, 1)}.ti{padding:32px 0}.tj{background-color:rgba(0, 0, 0, 0.9)}.tl:hover{color:rgba(255, 255, 255, 0.99)}.tm:hover{fill:rgba(255, 255, 255, 0.99)}.tn:disabled{color:rgba(255, 255, 255, 0.7)}.to:disabled{fill:rgba(255, 255, 255, 0.7)}.tp{height:22px}.tq{color:rgba(255, 255, 255, 0.7)}.tr{width:200px}.tt{color:rgba(255, 255, 255, 0.98)}.tu:hover{text-decoration:underline}.tz{margin-right:16px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.as{margin:0 64px}.hi{margin-top:32px}.iy{font-size:46px}.iz{margin-top:0.6em}.ja{line-height:56px}.jb{letter-spacing:-0.011em}.jt{margin-left:30px}.kq{font-size:21px}.kr{line-height:32px}.ks{letter-spacing:-0.003em}.kz{margin-top:2em}.lz{font-size:30px}.ma{margin-top:1.95em}.mb{line-height:36px}.mc{letter-spacing:0}.mi{margin-top:0.86em}.mo{margin-top:56px}.ne{margin-top:1.05em}.oh{margin-right:5px}.oy{margin-top:5px}.pj{padding-left:6px}.qa{font-size:22px}.qb{line-height:28px}.qo{font-size:16px}.qp{line-height:24px}.rd{display:inline-block}.ri{margin-left:7px}.rj{margin-top:8px}.ro{width:25px}.rw{padding-left:7px}.rx{top:3px}.ss{font-size:20px}.st{max-height:24px}.te{margin:0}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ib{margin-left:auto}.ic{text-align:center}.js{margin-left:30px}.og{margin-right:5px}.ox{margin-top:5px}.pi{padding-left:6px}.rc{display:inline-block}.rg{margin-left:7px}.rh{margin-top:8px}.rn{width:25px}.ru{padding-left:7px}.rv{top:3px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.jr{margin-left:30px}.of{margin-right:5px}.ow{margin-top:5px}.pg{padding-left:6px}.ph{top:3px}.ra{display:inline-block}.re{margin-left:7px}.rf{margin-top:8px}.rm{width:15px}.rt{padding-left:3px}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.u{margin-bottom:20px}.af{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.ag{min-height:230px}.ak{display:block}.bx{min-height:98px}.by{display:flex}.bz{align-items:flex-start}.ca{flex-direction:column}.cb{justify-content:flex-end}.cg{margin-bottom:28px}.ch{margin-top:0px}.ck{margin-top:28px}.ep{margin:0}.fz{border-top:1px solid rgba(230, 230, 230, 1)}.ga{border-bottom:1px solid rgba(230, 230, 230, 1)}.gj{align-items:center}.gk{flex:1 0 auto}.jf{margin-top:32px}.jg{flex-direction:column-reverse}.jp{margin-bottom:30px}.jq{margin-left:0px}.oe{margin-left:8px}.ou{margin-top:2px}.ov{margin-right:8px}.pe{padding-left:6px}.pf{top:3px}.pq{padding:24px 24px 28px 24px}.qz{display:inline-block}.rl{width:15px}.rs{padding-left:3px}.sg{padding-top:0}.sh{border-top:none}.tk{padding:32px 0}.ts{width:140px}.tv{margin-bottom:16px}.tw{margin-top:30px}.tx{width:100%}.ty{flex-direction:row}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.ao{margin:0 24px}.he{margin-top:24px}.ii{font-size:32px}.ij{margin-top:0.64em}.ik{line-height:40px}.il{letter-spacing:-0.016em}.je{margin-top:32px}.jn{margin-bottom:30px}.jo{margin-left:0px}.ke{font-size:18px}.kf{line-height:28px}.kg{letter-spacing:-0.003em}.kv{margin-top:1.56em}.ll{font-size:22px}.lm{margin-top:1.2em}.ln{letter-spacing:0}.me{margin-top:0.67em}.mk{margin-top:40px}.na{margin-top:1.34em}.od{margin-left:8px}.os{margin-top:2px}.ot{margin-right:8px}.pc{padding-left:6px}.pd{top:3px}.ps{font-size:20px}.pt{line-height:24px}.qg{font-size:14px}.qh{line-height:20px}.qr{margin:10px 0 0 0}.qy{display:inline-block}.rk{width:15px}.rr{padding-left:3px}.sk{font-size:16px}.sl{max-height:20px}.ta{margin:0}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ar{margin:0 64px}.hh{margin-top:32px}.iu{font-size:46px}.iv{margin-top:0.6em}.iw{line-height:56px}.ix{letter-spacing:-0.011em}.kn{font-size:21px}.ko{line-height:32px}.kp{letter-spacing:-0.003em}.ky{margin-top:2em}.lv{font-size:30px}.lw{margin-top:1.95em}.lx{line-height:36px}.ly{letter-spacing:0}.mh{margin-top:0.86em}.mn{margin-top:56px}.nd{margin-top:1.05em}.py{font-size:22px}.pz{line-height:28px}.qm{font-size:16px}.qn{line-height:24px}.sq{font-size:20px}.sr{max-height:24px}.td{margin:0}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.aq{margin:0 48px}.hg{margin-top:32px}.iq{font-size:46px}.ir{margin-top:0.6em}.is{line-height:56px}.it{letter-spacing:-0.011em}.kk{font-size:21px}.kl{line-height:32px}.km{letter-spacing:-0.003em}.kx{margin-top:2em}.lr{font-size:30px}.ls{margin-top:1.95em}.lt{line-height:36px}.lu{letter-spacing:0}.mg{margin-top:0.86em}.mm{margin-top:56px}.nc{margin-top:1.05em}.pw{font-size:22px}.px{line-height:28px}.qk{font-size:16px}.ql{line-height:24px}.so{font-size:20px}.sp{max-height:24px}.tc{margin:0}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ap{margin:0 24px}.hf{margin-top:24px}.im{font-size:32px}.in{margin-top:0.64em}.io{line-height:40px}.ip{letter-spacing:-0.016em}.kh{font-size:18px}.ki{line-height:28px}.kj{letter-spacing:-0.003em}.kw{margin-top:1.56em}.lo{font-size:22px}.lp{margin-top:1.2em}.lq{letter-spacing:0}.mf{margin-top:0.67em}.ml{margin-top:40px}.nb{margin-top:1.34em}.pu{font-size:20px}.pv{line-height:24px}.qi{font-size:14px}.qj{line-height:20px}.sm{font-size:16px}.sn{max-height:20px}.tb{margin:0}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="print">.ju{display:none}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.gg{animation:k2 .2s ease-in-out both}.hk{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.nl{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 1230px)">.nm{display:none}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="all and (max-width: 1198px)">.no{display:none}</style><style type="text/css" data-fela-rehydration="545" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.sx{max-height:none}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><div class="s"><div class="t s u"><div class="ac ae s af ag"><div class="n ah ai"><div class="aj ak"><div class="al s am an"><div class="n p"><div class="ao ap aq ar as at au v"><div class="av n o"><div class="n o aw ax"><div class="ay" id="li-ShowPostUnderCollection-navbar-open-in-app-button"><div class="az aj ak"><span class="ba b bb bc bd"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa7d96da06e20&amp;~feature=LiOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=post_page-----a7d96da06e20--------------------------------" class="be bf bg bh bi bj bk bl bm bn bo bp bq br bs" rel="noopener nofollow">Open in app</a></span></div></div></div><a href="https://medium.com/?source=post_page-----a7d96da06e20--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="bt bu"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="n p"><div class="ao ap aq ar as at au v"><div class="bv n o aw bw bx by bz ca cb"><div class="v n cc bw"><div class="n v"><div class="cd ce v n o aw cf cg ch by bz ca"><div class="ci cj s ck"><a href="/?source=post_page-----a7d96da06e20--------------------------------" aria-label="Publication Homepage" rel="noopener"><div class="q cl s"><img alt="Towards Data Science" class="" src="https://miro.medium.com/max/224/1*AGyTPCaRzVqL77kFwUwHKg.png" width="112" height="35"/></div></a></div></div></div><div class="n o cm cn an g"><div class="co cp cq n o"><div class="cr cs"><div class="n" aria-hidden="false"><button aria-label="Publication Menu" class="cv cw bg bh bi bj bk bl bm cx bn"><div class="cy s"><svg class="ct cu" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></div></button></div></div><div class="cz da s"><div class="cr cs"><div class="dh" aria-hidden="false"><div class="n"><button class="cv ds bg bh bi bj bk bl bm bn dt du bq dv dw"><span class="cy s"><svg width="25" height="25" viewBox="0 0 25 25" class="ct"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></span></button><input class="di cx dj dk bc dl dm dn do am dp dq dr" placeholder="Search Towards Data Science" value=""/></div></div></div></div><div class="ay" id="li-post-page-navbar-upsell-button"><div class="co s g"><div><a href="https://medium.com/plans?source=upgrade_membership---nav_full----------------------------------" class="ba b bb bc dn dx bu dy dz ea cu eb bn ec ed ee ef eg eh ei ej ek dh el" rel="noopener">Upgrade</a></div></div></div></div><a href="https://medium.com/?source=post_page-----a7d96da06e20--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="bt em"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><div class="s ak"><div class="n p"><div class="ao ap aq ar as at au v"><div class="w x y z ab"><div class="en eo n o"><div class="s ep"><span class="ba b dk eq er es et eu ev ew ex ey ez"><div class="n o"><div class="fa s"><div class="fb fc s"><div class="dh" aria-hidden="false"><button class="ba b bb bc fd fe ff fg fh fi fj bn ec ed fk fl eh ei ej ek dh el"><div class="n aw">Follow</div></button></div></div></div><div class="co fm ah"><a class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener" href="/followers?source=post_page-----a7d96da06e20--------------------------------">533K Followers</a></div><div class="fr s g">·</div><div class="fr s g"><nav class="n o"><span class="fs n ah"><a href="https://towardsdatascience.com/tagged/editors-pick?fromNav=true&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener">Editors&#x27; Picks</a></span><span class="fs n ah"><a href="https://towardsdatascience.com/tagged/tds-features?fromNav=true&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener">Features</a></span><span class="fs n ah"><a href="https://towardsdatascience.com/tagged/tds-explore?fromNav=true&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener">Explore</a></span><span class="fs n ah"><a class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener" href="/questions-96667b06af5?source=post_page-----a7d96da06e20--------------------------------">Contribute</a></span></nav></div><div class="fr n ah g"><a href="/about?source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener">About</a></div></div></span></div><div class="aj ft fu ak"><button class="n o p fv fw dp fx" aria-label="Expand navbar"><svg width="14" height="14" class="fy"><path d="M0 .5h14M0 7h14M0 13.5h14"></path></svg></button></div></div></div></div></div></div></div><div class="gh s"><div class="fz ga gb al c gc dl gd ge gf ay an gg"><div class="n p"><div class="ao ap aq ar as at au v"><div class="gi v aj gf an by gj"><div class="aj by gj gk"><div class="ay" id="li-ShowPostUnderCollection-navbar-open-in-app-button"><div class="az aj ak"><span class="ba b bb bc ez"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa7d96da06e20&amp;~feature=LiOpenInAppButton&amp;~channel=ShowPostUnderCollection&amp;~stage=mobileNavBar&amp;source=post_page-----a7d96da06e20--------------------------------" class="gl gm bg bh bi bj bk bl bm bn gn go bq br bs" rel="noopener nofollow">Open in app</a></span></div></div></div><a href="https://medium.com/?source=post_page-----a7d96da06e20--------------------------------" aria-label="Homepage" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="bt r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><article><section class="gp gq gr gs v gt ek s"></section><span class="s"></span><div><div class="ft gc gu gv gw gx"></div><section class="gy gz ha ew hb"><div class="n p"><div class="ao ap aq ar as hc au v"><figure class="he hf hg hh hi hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs hd"><div class="hs s am ht"><div class="hu hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*TnSDLVixRZfGZksBLT7kMA.jpeg?q=20" width="4950" height="2000"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="4950" height="2000"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/9900/1*TnSDLVixRZfGZksBLT7kMA.jpeg" width="4950" height="2000" srcSet="https://miro.medium.com/max/552/1*TnSDLVixRZfGZksBLT7kMA.jpeg 276w, https://miro.medium.com/max/1104/1*TnSDLVixRZfGZksBLT7kMA.jpeg 552w, https://miro.medium.com/max/1280/1*TnSDLVixRZfGZksBLT7kMA.jpeg 640w, https://miro.medium.com/max/1400/1*TnSDLVixRZfGZksBLT7kMA.jpeg 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="hz ia gt gr gs ib ic ba b bb bc ez">Photo by <a href="https://unsplash.com/photos/9hhOVsf1lpU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="cv id" target="_blank" rel="noopener nofollow">Blake Weyland</a> on <a href="https://unsplash.com/search/photos/matryoshka?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="cv id" target="_blank" rel="noopener nofollow">Unsplash</a></figcaption></figure><div class=""><h1 id="052e" class="ie if ig ba ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd">Boost your CNN image classifier performance with progressive resizing in Keras</h1><div class="ci"><div class="n bw je jf jg"><div class="o n"><div><a href="https://medium.com/@aleksey.bilogur?source=post_page-----a7d96da06e20--------------------------------" rel="noopener"><img alt="Aleksey Bilogur" class="s jh ji jj" src="https://miro.medium.com/fit/c/56/56/1*P57nj94yF-yIPrWJ70GOLg.jpeg" width="28" height="28"/></a></div><div class="fr v n cf"><div class="n"><div style="flex:1"><span class="ba b bb bc jd"><a href="https://medium.com/@aleksey.bilogur?source=post_page-----a7d96da06e20--------------------------------" class="" rel="noopener"><h4 class="ba b bb bc gl">Aleksey Bilogur</h4></a></span></div></div><span class="ba b bb bc ez"><a class="" rel="noopener" href="/boost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20?source=post_page-----a7d96da06e20--------------------------------"><h4 class="ba b bb bc ez"><span class="jk"></span>Apr 2, 2019<span class="jl">·</span>8 min read</h4></a></span></div></div><div class="n jm jn jo jp jq jr js jt ju"><div class="n o"><div class="jv s"><div class="dh" aria-hidden="false"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="jw s"><div><div class="jx"><div><div class="dh" role="tooltip" aria-hidden="false"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="Bookmark Post"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="jy s ax"><div class="dh" aria-hidden="false"><div class="dh" aria-hidden="false"><div class="s cm"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="More options"><svg class="r jz ka" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div><p id="e741" class="kb kc ig kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku gy jd">If you’re building an image classifier these days, you’re probably using a <a href="https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050" class="cv id" target="_blank" rel="noopener nofollow">convolutional neural network</a> to do it. CNNs are a type of neural network which build progressively higher level features out of groups of pixels commonly found in the images. How an image scores on these features is then weighted to generate a final classification result. CNNs are the best image classifier algorithm we know of, and they work particularly well when given lots and lots of data to work with.</p><p id="740e" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd"><strong class="kd ih">Progressive resizi<span id="rmm">n</span>g </strong>is a technique for building CNNs that can be very helpful during the training and optimization phases of a machine learning project. The technique appears most prominently in Jeremy Howard’s work, and he uses it to good effect throughout his terrific <code class="ht la lb lc ld b">fast.ai</code> course, “<a href="https://course.fast.ai/" class="cv id" target="_blank" rel="noopener nofollow">Deep Learning for Coders</a>”.</p><p id="5023" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">In this article I’ll demonstrate how you can use progressive resizing to build an image classifier using <a href="https://keras.io/" class="cv id" target="_blank" rel="noopener nofollow">Keras</a>. Specifically, we’ll using progressive resizing to build a CNN that learns to distinguish between 12 different kinds of fruits in what I call the Open Fruits dataset — an image corpus I built based on the Google Open Images dataset (to learn more about Google Open Images, read “<a href="https://blog.quiltdata.com/how-to-classify-photos-in-600-classes-using-nine-million-open-images-3cdb989ad1c2" class="cv id" target="_blank" rel="noopener nofollow">How to classify photos in 600 classes using nine million open images</a>”).</p><p id="4a9c" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">You can follow along with the code and learn how to download the data <a href="https://github.com/ResidentMario/progressive-resizing" class="cv id" target="_blank" rel="noopener nofollow">on GitHub</a>.</p><blockquote class="le lf lg"><p id="af3a" class="kb kc lh kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This post assumes familiarity with CNNs. If you’re unfamiliar, Brandon Rohrer’s “<a href="https://brohrer.github.io/how_convolutional_neural_networks_work.html" class="cv id" target="_blank" rel="noopener nofollow">How convolutional neural networks work</a>” is excellent background reading.</p></blockquote><h1 id="5e32" class="li lj ig ba lk ll lm kf ln lo lp ki lq lr ls lt lu lv lw lx ly lz ma mb mc md jd">Checking out the data</h1><p id="e6eb" class="kb kc ig kd b ke me kf kg kh mf ki kj kk mg kl km kn mh ko kp kq mi kr ks ku gy jd">Recall that our dataset consists of images of 12 different kinds of fruits taken from <a href="https://github.com/openimages/dataset" class="cv id" target="_blank" rel="noopener nofollow">Google Open Images</a>, which is in turn based on permissively-licensed images from <a href="https://www.flickr.com/" class="cv id" target="_blank" rel="noopener nofollow">Flickr</a>. To get a taste, here’s 25 random images from the dataset:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs mj"><div class="hs s am ht"><div class="mp hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*7d0EAGgLTtrGFp5EvMtDLA.png?q=20" width="1166" height="1122"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="1166" height="1122"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/2332/1*7d0EAGgLTtrGFp5EvMtDLA.png" width="1166" height="1122" srcSet="https://miro.medium.com/max/552/1*7d0EAGgLTtrGFp5EvMtDLA.png 276w, https://miro.medium.com/max/1104/1*7d0EAGgLTtrGFp5EvMtDLA.png 552w, https://miro.medium.com/max/1280/1*7d0EAGgLTtrGFp5EvMtDLA.png 640w, https://miro.medium.com/max/1400/1*7d0EAGgLTtrGFp5EvMtDLA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="3ce8" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Right away we see that this dataset is very problematic. It includes tiny images; occluded images that only depict parts of the sample; samples depicting groups of objects instead of individual ones; and bounding boxes that are just plain noisy and may not even be constrained to a single type of fruit. In a few of the cases it’s difficult even for a human to distinguish what the target class is.</p><p id="8513" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">To add to the difficulty, the dataset is highly imbalanced, with some image classes appearing far more often than others:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs mq"><div class="hs s am ht"><div class="mr hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*zOdNhSVX1EkBNTavpk79Hw.png?q=20" width="735" height="575"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="735" height="575"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/1470/1*zOdNhSVX1EkBNTavpk79Hw.png" width="735" height="575" srcSet="https://miro.medium.com/max/552/1*zOdNhSVX1EkBNTavpk79Hw.png 276w, https://miro.medium.com/max/1104/1*zOdNhSVX1EkBNTavpk79Hw.png 552w, https://miro.medium.com/max/1280/1*zOdNhSVX1EkBNTavpk79Hw.png 640w, https://miro.medium.com/max/1400/1*zOdNhSVX1EkBNTavpk79Hw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="9011" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Between the low image and label quality and the class sparsity this classification problem is a very, very difficult one.</p><h1 id="5b00" class="li lj ig ba lk ll lm kf ln lo lp ki lq lr ls lt lu lv lw lx ly lz ma mb mc md jd">Start small to iterate quickly</h1><p id="9344" class="kb kc ig kd b ke me kf kg kh mf ki kj kk mg kl km kn mh ko kp kq mi kr ks ku gy jd">Now that we understand the contents of our dataset, we need to make choices about the network we will train.</p><p id="5626" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">One trouble is that a single neural network can only work with standardly-sized images; too-small images must be scaled up and too-large images must be scaled down. But what image size should be pick?</p><p id="d299" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">If your goal is model accuracy, larger is obviously better. <strong class="kd ih">But there is a lot of advantage to starting small</strong>.</p><p id="fb6a" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">To understand why, we must first understand that the most important features of an image classification problem are “large”. Properly tuned gradient descent naturally favors robust, well-supported features in its decision-making. In the image classification case this translates into features occupying as many pixels in as many of the sample images as possible.</p><p id="7e3f" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">For example, suppose we teach a neural network to distinguish between oranges and apples. Suppose that one model classifies by distinguishing between “orange” and “red”, and another classifies by distinguishing between “stem shaped like an orange stem” and “stem shaped like an apple stem”. The first model is robust: <em class="lh">any </em>image we score, no matter how small or misshaped, will have orange pixels and red pixels usable by the model. The second model is not: we can image images so small that the stems are not easily distinguishable, or images with the stem cropped out, or images where the stems have been removed outright.</p><p id="6f8c" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">The practical result is that while a model trained on very small images will learn fewer features than one trained on very large images, the ones that it <em class="lh">does </em>learn will be the most important ones. Thus a model architecture that works on small images will generalize to larger ones.</p><p id="2c66" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Meanwhile, small-image models are <em class="lh">much </em>faster to train. After all an image input size twice as large has four times as many pixels to learn on!</p><p id="8e1e" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Since small-image models generalize well to larger input sizes, and since they take less time to train, and since the first batch of models we build are going to be highly experimental anyway, why don’t we save time and just train our first few models on small data, and worry about scaling up the images and the models later?</p><p id="0a98" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">In fact, that is <em class="lh">exactly</em> what progressive resizing is!</p><p id="8829" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">We now understand the main idea behind progressive resizing. Let’s see how it works in practice.</p><h1 id="cf33" class="li lj ig ba lk ll lm kf ln lo lp ki lq lr ls lt lu lv lw lx ly lz ma mb mc md jd">Our first tiny model</h1><p id="13ad" class="kb kc ig kd b ke me kf kg kh mf ki kj kk mg kl km kn mh ko kp kq mi kr ks ku gy jd">We start out by building our first small-scale model.</p><p id="55f8" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Here is a smoothed <a href="https://seaborn.pydata.org/generated/seaborn.kdeplot.html" class="cv id" target="_blank" rel="noopener nofollow">kernel-density plot</a> of image sizes in our “Open Fruits” dataset:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs ms"><div class="hs s am ht"><div class="mt hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*kta4aX_8Dl5IYt9-Zo8bdw.png?q=20" width="759" height="494"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="759" height="494"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/1518/1*kta4aX_8Dl5IYt9-Zo8bdw.png" width="759" height="494" srcSet="https://miro.medium.com/max/552/1*kta4aX_8Dl5IYt9-Zo8bdw.png 276w, https://miro.medium.com/max/1104/1*kta4aX_8Dl5IYt9-Zo8bdw.png 552w, https://miro.medium.com/max/1280/1*kta4aX_8Dl5IYt9-Zo8bdw.png 640w, https://miro.medium.com/max/1400/1*kta4aX_8Dl5IYt9-Zo8bdw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="3db5" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">We see here that the images peak at around <code class="ht la lb lc ld b">128x128</code> in size. So for our initial input size we will choose 1/3 of that: <code class="ht la lb lc ld b">48x48</code>.</p><p id="c664" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Now it’s time to experiment! What kind of model you end up building in this phase of the project is entirely up to you. Here’s what I did (with comments in the code):</p><figure class="mk ml mm mn mo hj"><div class="hs s am"><div class="mu hv s"></div></div></figure><p id="66af" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This model achieved ~53% validation accuracy:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs mv"><div class="hs s am ht"><div class="mw hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*jlSwmz5yZyLLIHgwPlu_-w.png?q=20" width="800" height="600"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="800" height="600"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/1600/1*jlSwmz5yZyLLIHgwPlu_-w.png" width="800" height="600" srcSet="https://miro.medium.com/max/552/1*jlSwmz5yZyLLIHgwPlu_-w.png 276w, https://miro.medium.com/max/1104/1*jlSwmz5yZyLLIHgwPlu_-w.png 552w, https://miro.medium.com/max/1280/1*jlSwmz5yZyLLIHgwPlu_-w.png 640w, https://miro.medium.com/max/1400/1*jlSwmz5yZyLLIHgwPlu_-w.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="f25e" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Not stellar, but remember, this is a very simple model trained on very small very noisy images, with a lot of classes to choose from. We could do better by working on this model further, but I only had so much time to iterate on this model. 😅</p><h1 id="ac38" class="li lj ig ba lk ll lm kf ln lo lp ki lq lr ls lt lu lv lw lx ly lz ma mb mc md jd">Applying progressive resizing</h1><p id="833d" class="kb kc ig kd b ke me kf kg kh mf ki kj kk mg kl km kn mh ko kp kq mi kr ks ku gy jd">We now apply progressive resizing to the problem.</p><p id="a6fd" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">We started by building a classifier that performs well on tiny <code class="ht la lb lc ld b">n x n</code> (48 x 48) images. The next step is scaling our model up to <code class="ht la lb lc ld b">2n x 2n</code> (96 x 96) images.</p><p id="f2cf" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">We do this using <strong class="kd ih">transfer learning</strong>. Transfer learning is the technique of re-using layers and weights from previous models when building new ones (“<a class="cv id" target="_blank" rel="noopener" href="/keras-transfer-learning-for-beginners-6c9b8b7143e">Deep Learning For Beginners Using Transfer Learning In Keras</a>” provides a good overview). In our case, this will mean taking the model we just built, freezing it (so that further training won’t make any changes to our existing weights), and injecting its layers into a new model (one which takes upscaled 96 x 96 images as input).</p><p id="1ce7" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">The work we do at this stage is limited to finding a configuration of good “feeder layers” we can prefix our old model with. These new layers can focus on finding the additional features findable in 96 x 96 pixels that weren’t in 48 x 48 pixels.</p><p id="9188" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">First I saved the 48 x 48 model to disk as <code class="ht la lb lc ld b">model-48.h5</code>. Then I created the following new model:</p><figure class="mk ml mm mn mo hj"><div class="hs s am"><div class="mu hv s"></div></div></figure><p id="2285" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This script:</p><ol class=""><li id="24e1" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku mx my mz jd">Downloads and instantiates our old 48 x 48 model.</li><li id="a7c8" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku mx my mz jd">Instantiates a new model with two new 96 x 96 convolutional layers.</li><li id="acaf" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku mx my mz jd">Appends a max pooling layer, which downsamples 96 x 96 → 48 x 48—the expected input size for our old model.</li><li id="deeb" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku mx my mz jd">Removes the first convolutional layer from our old model (by the way, this helps reduce overfit!).</li><li id="77fe" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku mx my mz jd">Reattaches the rest of the layers of our old model onto the new one.</li><li id="37a0" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku mx my mz jd">Freezes the old convolutional and fully-connected layer weights in place.</li></ol><p id="9624" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Basically, we’ve created a new model that trains on 96x96 pixel images <strong class="kd ih">which reuses our old 48 x 48 classifier internally</strong>!</p><p id="609c" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This new model improves performance from ~53% to ~59%:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs mv"><div class="hs s am ht"><div class="mw hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*bzyfBZvwWEO50DLwpMc0xA.png?q=20" width="800" height="600"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="800" height="600"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/1600/1*bzyfBZvwWEO50DLwpMc0xA.png" width="800" height="600" srcSet="https://miro.medium.com/max/552/1*bzyfBZvwWEO50DLwpMc0xA.png 276w, https://miro.medium.com/max/1104/1*bzyfBZvwWEO50DLwpMc0xA.png 552w, https://miro.medium.com/max/1280/1*bzyfBZvwWEO50DLwpMc0xA.png 640w, https://miro.medium.com/max/1400/1*bzyfBZvwWEO50DLwpMc0xA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="664b" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">We can apply progressive resizing one more time, this time moving from 96x96 to 192x192. The procedure required is the same, differing only in scale:</p><figure class="mk ml mm mn mo hj"><div class="hs s am"><div class="mu hv s"></div></div></figure><p id="ee8e" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This new model sees data that is fully sixteen times as large as our original tiny 48x48 model. This translates into further model improvement, but this time that benefit is more modest — up from 59% to 61%:</p><figure class="mk ml mm mn mo hj gr gs paragraph-image"><div role="button" tabindex="0" class="hk hl am hm v hn"><div class="gr gs mv"><div class="hs s am ht"><div class="mw hv s"><div class="dl ho ft gf gc hp v dg hq hr"><img alt="Image for post" class="ft gf gc hp v hw hx hy" src="https://miro.medium.com/max/60/1*RWQ34_N1fBYjOV6OfGQTSA.png?q=20" width="800" height="600"/></div><img alt="Image for post" class="dl ho ft gf gc hp v c" width="800" height="600"/><noscript><img alt="Image for post" class="ft gf gc hp v" src="https://miro.medium.com/max/1600/1*RWQ34_N1fBYjOV6OfGQTSA.png" width="800" height="600" srcSet="https://miro.medium.com/max/552/1*RWQ34_N1fBYjOV6OfGQTSA.png 276w, https://miro.medium.com/max/1104/1*RWQ34_N1fBYjOV6OfGQTSA.png 552w, https://miro.medium.com/max/1280/1*RWQ34_N1fBYjOV6OfGQTSA.png 640w, https://miro.medium.com/max/1400/1*RWQ34_N1fBYjOV6OfGQTSA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="8554" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">To summarize what we’ve done:</p><ul class=""><li id="7578" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku nf my mz jd">We started with a model that trained on tiny 48x48 pixel images, which is 53% accurate.</li><li id="14e5" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Next we trained a model on 96x96 pixel images, reusing our 48x48 classifier within our model and achieving 59% accuracy.</li><li id="2518" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Finally, we trained a model on 192x192 pixel images, reusing our 96x96 classifier (which in turn reused our 48x48 classifier!) and achieving 61% accuracy.</li></ul><p id="7458" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Note that, in the interest of time, I did not spend much time experimenting with the new layers I added in steps 2 and 3. To improve performance further, here are some other things you could try:</p><ul class=""><li id="d12e" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku nf my mz jd">Increasing or decreasing the number of new convolutional layers you add.</li><li id="1b95" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Increasing or decreasing the number of nodes in each new convolutional layer.</li><li id="bed3" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Tuning hyper-parameters like activation functions and learning rates.</li><li id="23a6" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Experimenting with the image preprocessing you apply.</li><li id="254f" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Unfreezing the fully-connected layer and adjusting/training that as well.</li><li id="5c09" class="kb kc ig kd b ke na kf kg kh nb ki kj kk nc kl km kn nd ko kp kq ne kr ks ku nf my mz jd">Unfreezing one or more preexisting convolutional layers and (re-)training those as well.</li></ul><h1 id="fa3a" class="li lj ig ba lk ll lm kf ln lo lp ki lq lr ls lt lu lv lw lx ly lz ma mb mc md jd">Conclusion</h1><p id="28e7" class="kb kc ig kd b ke me kf kg kh mf ki kj kk mg kl km kn mh ko kp kq mi kr ks ku gy jd">We started this article off by discussing the fact that convolutional neural networks trained on small images are both fast and easy to train and readily generalizable to larger image inputs. This makes them good models to build during the early experimental phase of a project, when you’re still just trying to get to grips with a basic network architecture that works well. We can concentrate on dashing off quick one-off models now, and on scaling them up and fine-tuning performance later. Finally, we heard that models trained this way can often achieve equal or better performance than models trained from scratch.</p><p id="dfff" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Consider the alternative: building and tuning a full-sized 196 x 196 model from the start. This model would have an unrestricted “model finding space”: it could theoretically converge on any combination of layer weights that works best for the given problem. Progressive resizing is much more restrictive: it require that a model that works well on <code class="ht la lb lc ld b">2n x 2n</code> images must subsume a model that works well on <code class="ht la lb lc ld b">n x n</code>.</p><p id="b737" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">This could in theory mean that we “miss” an even better architecture that a model built from scratch could converge on. But in practice, models built using progressive resizing principles often actually do <em class="lh">better </em>than models built from scratch.</p><p id="e9cd" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">The theoretical reason why is a mystery. One compelling theory, courtesy of Miguel Perez Michaus, is that it improves the ability of the model to learn “scale-dependent” patterns. He writes about this in the excellent blog post “<a href="https://miguel-data-sc.github.io/2017-11-23-second/" class="cv id" target="_blank" rel="noopener nofollow">Yes, Convolutional Neural Nets do care about Scale</a>”; I recommend reading it if you want to learn more.</p><p id="42c1" class="kb kc ig kd b ke kv kf kg kh kw ki kj kk kx kl km kn ky ko kp kq kz kr ks ku gy jd">Nevertheless, progressive resizing is an interesting technique and a useful approach to image modeling problems And hopefully now that you have read this article, another useful tool in your deep learning toolbox. 😎</p></div></div></section></div></article><div class="dl gx gd ng v nn nl no" data-test-id="post-sidebar"><div class="n p"><div class="ao ap aq ar as at au v"><div class="np n ah"><div class="gx"><div><div class="nq nr s"><p class="ba b ns nt nu ez nv">Written by</p><div class="nw nx s"><a href="https://medium.com/@aleksey.bilogur?source=post_sidebar--------------------------post_sidebar-----------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener"><h2 class="ba lk dk bc if jd gy">Aleksey Bilogur</h2></a></div><div class="ny s"><h4 class="ba b bb bc ez">Building tools for doing data science. {📊, 💻, 🛠️}.</h4></div><div class="nz s"></div></div><div class="oa ob oc n"><div class="n o"><div class="s am od oe of og oh"><div class=""><div><div class="dh" role="tooltip" aria-hidden="false"><div class="bl oi oj ok ol om on oo r op oq or"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM18.63 2.22l-1.43-.47-.4 3.03zM11.79 1.75l-1.43.47 1.84 2.56zM24.47 14.3L21.45 9c-.29-.43-.69-.7-1.12-.78a1.16 1.16 0 0 0-.91.22c-.3.23-.48.52-.54.84l.05.07 2.85 5c1.95 3.56 1.32 6.97-1.85 10.14a8.46 8.46 0 0 1-.55.5 5.75 5.75 0 0 0 3.36-1.76c3.26-3.27 3.04-6.75 1.73-8.91M14.58 10.89c-.16-.83.1-1.57.7-2.15l-2.5-2.49c-.5-.5-1.38-.5-1.88 0-.18.18-.27.4-.33.63l4.01 4z"></path><path d="M17.81 10.04a1.37 1.37 0 0 0-.88-.6.81.81 0 0 0-.64.15c-.18.13-.71.55-.24 1.56l1.43 3.03a.54.54 0 1 1-.87.61L9.2 7.38a.99.99 0 1 0-1.4 1.4l4.4 4.4a.54.54 0 1 1-.76.76l-4.4-4.4L5.8 8.3a.99.99 0 0 0-1.4 0 .98.98 0 0 0 0 1.39l1.25 1.24 4.4 4.4a.54.54 0 0 1 0 .76.54.54 0 0 1-.76 0l-4.4-4.4a1 1 0 0 0-1.4 0 .98.98 0 0 0 0 1.4l1.86 1.85 2.76 2.77a.54.54 0 0 1-.76.76L4.58 15.7a.98.98 0 0 0-1.4 0 .99.99 0 0 0 0 1.4l5.33 5.32c3.37 3.37 6.64 4.98 10.49 1.12 2.74-2.74 3.27-5.54 1.62-8.56l-2.8-4.94z"></path></g></svg></div></div></div></div></div><div class="s os ot ou ov ow ox oy"><div class="oz"><h4 class="ba b bb bc ez"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq">1.4K<!-- --> </button></h4></div></div></div></div><div class="ob s"><button class="fx oj bl"><div class="pb n o aw"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg><div class="s am pc pd pe pf pg ph pi pj"><h4 class="ba b bb bc ez">8<!-- --> </h4></div></div></button></div><div><div class="jx"><div><div class="dh" role="tooltip" aria-hidden="false"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="Bookmark Post"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="dl gx ng gd nh ni nj nk nl nm"></div><div><div class="pk hj n ah p"><div class="n p"><div class="ao ap aq ar as hc au v"><div class="pl pm pn po pp pq"><div class="pr s"><h2 class="ba lk ps pt ln pu pv lq pw px lu py pz ly qa qb mc jd">Sign up for The Daily Pick</h2></div><div class="qc s"><h3 class="ba b qd bc jd">By Towards Data Science</h3></div><div class="qe qf s"><p class="ba b qg qh qi qj qk ql qm qn qo qp jd">Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.<!-- --> <a href="https://medium.com/towards-data-science/newsletters/the-daily-pick?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="cv ds bg bh bi bj bk bl bm bn bq fp fq id" rel="noopener">Take a look</a></p></div><div class="n cf"><div class="qq s qr"><button class="ba b dk eq fd qs ff fg fh fi fj bn ec ed fk fl eh ei ej ek dh el"><span class="jw" aria-hidden="true"><svg width="20" height="16" viewBox="0 0 20 16"><path d="M0 .35v15.3h20V.35H0zm6.95 9.38l3.05 2.5 3.05-2.5 4.88 4.73H2.07l4.88-4.73zM1.2 13.64V5.02l4.82 3.94-4.82 4.68zm12.78-4.68l4.82-3.94v8.62l-4.82-4.68zm4.82-7.42v1.94l-8.8 7.2-8.8-7.2V1.54h17.6z"></path></svg></span>Get this newsletter</button></div><div class="qt qu s"><p class="ba b qd bc jd">Emails will be sent to <!-- -->aleksey.bilogur@gmail.com<!-- -->.<div class="s"><span><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fboost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20&amp;source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener"><button class="cv ds bg bh bi bj bk bl bm bn bq fp fq id" target="_blank">Not you?</button></a></span></div></p></div></div></div><div class="n cf"></div><div class="n o cf"></div><div class="qv qw s"><div class="qw n bw ju"><div class="n aw"><div class="qx s"><span class="s qy qz ra e d"><div class="n o"><div class="s am od oe of og oh"><div class=""><div><div class="dh" role="tooltip" aria-hidden="false"><div class="bl oi oj ok ol om on oo r op oq or"><svg width="25" height="25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM16.63 1.22L15.2.75l-.4 3.03zM9.79.75l-1.43.47 1.84 2.56zM22.47 13.3L19.45 8c-.29-.43-.69-.7-1.12-.78a1.16 1.16 0 0 0-.91.22c-.3.23-.48.52-.54.84l.05.07 2.85 5c1.95 3.56 1.32 6.97-1.85 10.14a8.46 8.46 0 0 1-.55.5 5.75 5.75 0 0 0 3.36-1.76c3.26-3.27 3.04-6.75 1.73-8.91M12.58 9.89c-.16-.83.1-1.57.7-2.15l-2.5-2.49c-.5-.5-1.38-.5-1.88 0-.18.18-.27.4-.33.63l4.01 4z"></path><path d="M15.81 9.04a1.37 1.37 0 0 0-.88-.6.81.81 0 0 0-.64.15c-.18.13-.72.55-.24 1.56l1.43 3.03a.54.54 0 1 1-.87.61L7.2 6.38a.99.99 0 1 0-1.4 1.4l4.4 4.4a.54.54 0 1 1-.76.76l-4.4-4.4L3.8 7.3a.99.99 0 0 0-1.4 0 .98.98 0 0 0 0 1.39l1.25 1.24 4.4 4.4a.54.54 0 0 1 0 .76.54.54 0 0 1-.76 0l-4.4-4.4a1 1 0 0 0-1.4 0 .98.98 0 0 0 0 1.4l1.86 1.85 2.76 2.77a.54.54 0 0 1-.76.76L2.58 14.7a.98.98 0 0 0-1.4 0 .99.99 0 0 0 0 1.4l5.33 5.32c3.37 3.37 6.64 4.98 10.49 1.12 2.74-2.74 3.27-5.54 1.62-8.56l-2.8-4.94z"></path></g></svg></div></div></div></div></div><div class="s os ot ou ov ow ox oy"><div class="am rb oz"><h4 class="ba b bb bc jd"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq">1.4K<span class="s h g f rc rd"> </span></button><span class="s h g f rc rd"></span></h4></div></div></div></span><span class="s h g f rc rd"><div class="n cc"><div class="s am od oe"><div class=""><div><div class="dh" role="tooltip" aria-hidden="false"><div class="bl oi oj ok ol om on oo r op oq or"><svg width="33" height="33" aria-label="clap"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.85-6.78c-.37-.54-.88-.9-1.44-.99a1.5 1.5 0 0 0-1.16.28c-.42.33-.65.74-.7 1.2v.01l3.63 6.37c2.46 4.5 1.67 8.8-2.33 12.8-.27.27-.54.5-.81.73a7.55 7.55 0 0 0 4.45-2.26c4.16-4.17 3.87-8.6 2.21-11.36zm-4.83.82l-3.58-6.3c-.3-.44-.73-.74-1.19-.81a1.1 1.1 0 0 0-.89.2c-.64.51-.75 1.2-.33 2.1l1.83 3.86a.6.6 0 0 1-.2.75.6.6 0 0 1-.77-.07l-9.44-9.44c-.51-.5-1.4-.5-1.9 0a1.33 1.33 0 0 0-.4.95c0 .36.14.7.4.95l5.6 5.61a.6.6 0 1 1-.84.85l-5.6-5.6-.01-.01-1.58-1.59a1.35 1.35 0 0 0-1.9 0 1.35 1.35 0 0 0 0 1.9l1.58 1.59 5.6 5.6a.6.6 0 0 1-.84.86L4.68 13.7c-.51-.51-1.4-.51-1.9 0a1.33 1.33 0 0 0-.4.95c0 .36.14.7.4.95l2.36 2.36 3.52 3.52a.6.6 0 0 1-.84.85l-3.53-3.52a1.34 1.34 0 0 0-.95-.4 1.34 1.34 0 0 0-.95 2.3l6.78 6.78c3.72 3.71 9.33 5.6 13.5 1.43 3.52-3.52 4.2-7.13 2.08-11.01zM11.82 7.72c.06-.32.21-.63.46-.89a1.74 1.74 0 0 1 2.4 0l3.23 3.24a2.87 2.87 0 0 0-.76 2.99l-5.33-5.33zM13.29.48l-1.92.88 2.37 2.84zM21.72 1.36L19.79.5l-.44 3.7zM16.5 3.3L15.48 0h2.04z"></path></g></svg></div></div></div></div></div><div class="s os ot ou ov re rf rg rh ri rj"><div class="am rb oz"><h4 class="ba b bb bc jd"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq">1.4K<span class="s h g f rc rd"> </span></button><span class="s h g f rc rd"></span></h4></div></div></div></span></div><div class="s rk rl rm rn ro"></div><button class="fx oj bl"><div class="pb n o aw"><div><div class="dh" role="tooltip" aria-hidden="false"><span class="rp s h g f rc rd"><svg width="33" height="33" viewBox="0 0 33 33" fill="none" class="r" aria-label="responses"><path clip-rule="evenodd" d="M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z"></path></svg></span><span class="rq s qy qz ra e d"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></span></div></div><div class="s am rr pd rs pf rt ph ru rv rw rx"><h4 class="ba b bb bc jd">8<!-- --> </h4></div></div></button></div><div class="n o"><div class="jv s"><div class="dh" aria-hidden="false"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="ry s cm"><div><div class="jx"><div><div class="dh" role="tooltip" aria-hidden="false"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="Bookmark Post"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="dh" aria-hidden="false"><div class="dh" aria-hidden="false"><div class="s cm"><button class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" aria-label="More options"><svg class="r jz ka" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div><div class="rz qw s"><ul class="bl bm"><li class="dh sa jw sb"><a href="/tagged/machine-learning" class="ba b qd sc ez sd se el s sf">Machine Learning</a></li><li class="dh sa jw sb"><a href="/tagged/keras" class="ba b qd sc ez sd se el s sf">Keras</a></li><li class="dh sa jw sb"><a href="/tagged/cnn" class="ba b qd sc ez sd se el s sf">Cnn</a></li><li class="dh sa jw sb"><a href="/tagged/optimization" class="ba b qd sc ez sd se el s sf">Optimization</a></li><li class="dh sa jw sb"><a href="/tagged/fastai" class="ba b qd sc ez sd se el s sf">Fastai</a></li></ul></div></div></div><div><div class="n p"><div class="ao ap aq ar as hc au v"><div class="s sg sh ju"></div></div></div><div class="s ju"><div class="si sj s pp"><div class="n p"><div class="ao ap aq ar as hc au v"><div class="n o bw"><h2 class="ba lk sk qh sl ln sm qj sn lq so ql sp lu sq qn sr ly ss qp st mc dg df su sv sw sx jd"><a href="https://towardsdatascience.com/?source=follow_footer-------------------------------------" class="cv ds bg bh bi bj bk bl bm bn fn fo bq fp fq" rel="noopener">More from Towards Data Science</a></h2><div class="dh" aria-hidden="false"><button class="ba b bb bc fd dx ff fg fh fi fj bn ec ed fk fl eh ei ej ek dh el"><div class="n aw">Follow</div></button></div></div><div class="nx sy s"><h4 class="ba b bb bc ez">A Medium publication sharing concepts, ideas, and codes.</h4></div></div></div></div></div><div class="sz s pp ju"><div class="n p"><div class="ta tb tc td te tf au v"><div class="tg pk s"><div class="tf s ia"><a href="https://towardsdatascience.com/?source=follow_footer-------------------------------------" class="ba b bb bc fd fe ff fg fh fi fj bn ec ed fk fl eh ei ej ek dh el" rel="noopener">Read more from <!-- -->Towards Data Science</a></div></div></div></div></div><div class="s th ju"><div class="n p"><div class="ao ap aq ar as at au v"></div></div></div></div></div></div><div class="ti s tj tk"><div class="n p"><div class="ao ap aq ar as at au v"><div class="n ah"><div class="n o bw"><a href="https://medium.com/?source=post_page-----a7d96da06e20--------------------------------" aria-label="Go to homepage" class="cv ds bg bh bi bj bk bl bm bn tl tm bq tn to" rel="noopener"><svg viewBox="0 0 3940 610" class="ff tp"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><h4 class="ba b bb bc tq"><div class="qf tr n bw ts by"><h4 class="ba b dk eq tt"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn tu bq tn to" rel="noopener">About</a></h4><h4 class="ba b dk eq tt"><a href="https://help.medium.com/hc/en-us?source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn tu bq tn to" rel="noopener">Help</a></h4><h4 class="ba b dk eq tt"><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn tu bq tn to" rel="noopener">Legal</a></h4></div></h4></div><div class="aj tv tw by"><h4 class="ba b dk eq tq">Get the Medium app</h4></div><div class="aj tv tx by ty"><div class="tz s"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn tl tm bq tn to" rel="noopener nofollow"><img alt="A button that says &#x27;Download on the App Store&#x27;, and if clicked it will lead you to the iOS App store" class="" src="https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"/></a></div><div class="s"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----a7d96da06e20--------------------------------" class="cv ds bg bh bi bj bk bl bm bn tl tm bq tn to" rel="noopener nofollow"><img alt="A button that says &#x27;Get it on, Google Play&#x27;, and if clicked it will lead you to the Google Play store" class="" src="https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"/></a></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = "main-20210115-211454-7fb6ff250f"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"auroraPage":{"isAuroraPageEnabled":true},"config":{"nodeEnv":"production","version":"main-20210115-211454-7fb6ff250f","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20210115-211454-7fb6ff250f"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"main-20210115-211454-7fb6ff250f","commit":"7fb6ff250fe43fb6fe50c022cd3444d92855bbce"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e","9dc80918cc93","8a9336e5bb4","cef6983b292","54c98c43354d","193b68bd4fba","b7e45b22fec3","55760f21cdc5"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","errorTracking":"none"},"debug":{"requestId":"e63a38c7-2b19-4d47-a2c1-40c1b10ebd0d","branchDeployConfig":null,"originalSpanCarrier":{"ot-tracer-spanid":"60987e905b6f34c4","ot-tracer-traceid":"7e17fa114ba5fed1","ot-tracer-sampled":"true"}},"session":{"user":{"id":"b6d2cfb88f3"},"xsrf":"7866ef70b26e","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fboost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fmedium.com\u002Fme\u002Fstories\u002Fpublic","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isEu":false,"isUs":true,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"inAppBrowserName":"","routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"supportsWebp":false,"useNeedForSpeed":false},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"android_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"assign_default_topic_to_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"bane_add_user","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bane_verify_domain","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"branch_seo_metadata","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"default_seo_post_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_android_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_resume_reading_toast","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_post_recommended_from_friends_provider","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_local_currency","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_parse_expires_at","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_failure","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_general_admission","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_follow_pages","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_sticky_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_autotier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automated_mission_control_triggers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding_fonts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cleansweep_double_writes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_client_error_tracking","valueType":{"__typename":"VariantFlagString","value":"none"}},{"__typename":"VariantFlag","name":"enable_confirm_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cta_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_curation_priority_queue_experiment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_daily_read_digest_promo","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dedicated_series_tab_api_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_feature_logging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_earn_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_edit_alt_text","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_to_subscribers_after_publish","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_embedding_based_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_end_of_post_cleanup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_expire_processor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_from_authors_you_may_enjoy","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_fyf_authors_and_collections","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_global_susi_modal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_write_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_increased_digest_timeout","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_post_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_json_logs_trained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_app_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_daily_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_lo_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notifications","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pay_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_cd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights_view_only","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_unread_notification_count_mutation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_media_resource_try_catch","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_remove_section_a","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_miro_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mission_control","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_checkout_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_collaborative_filtering_data","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_no_name_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_parsely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_patronus_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_popularity_feature","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_page_nav_stickiness_removal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_primary_topic_for_mobile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_design_reminder","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_page_seo_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_edit_and_delete","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_moderation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rtr_channel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_s3_sites","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_save_to_medium","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sohne","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace_ranker_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ticks_digest_promo","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_topic_lifecycle_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trending_posts_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_predictions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_unbound","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"google_sign_in_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_generic_home_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_iceland_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_pub_follow_email_opt_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"is_not_medium_subscriber","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_fastrak","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_stripe_express","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"make_nav_sticky","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"new_transition_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"provider_for_credit_card_form","valueType":{"__typename":"VariantFlagString","value":"BRAINTREE"}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefine_average_post_reading_time","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_post_post_similarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"retrained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sign_up_with_email_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"suppress_apple_missing_expires_date_alert","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"use_new_admin_topic_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"viewer":{"__ref":"User:b6d2cfb88f3"},"meterPost({\"postId\":\"a7d96da06e20\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fmedium.com\u002Fme\u002Fstories\u002Fpublic\"}})":{"__ref":"MeteringInfo:{}"},"postResult({\"id\":\"a7d96da06e20\"})":{"__ref":"Post:a7d96da06e20"}},"User:b6d2cfb88f3":{"id":"b6d2cfb88f3","__typename":"User","username":"aleksey.bilogur","name":"Aleksey Bilogur","imageId":"1*P57nj94yF-yIPrWJ70GOLg.jpeg","mediumMemberAt":0,"hasPastMemberships":false,"isPartnerProgramEnrolled":false,"email":"aleksey.bilogur@gmail.com","unverifiedEmail":"","createdAt":1485660812058,"isAuroraVisible":true,"isEligibleToViewNewResponses":true,"isMembershipTrialEligible":true,"isSuspended":true,"styleEditorOnboardingVersionSeen":0,"allowEmailAddressSharingEditorWriter":false,"hasDomain":false,"dismissableFlags":["FOLLOWERS_TOOLTIP"],"hasCompletedProfile":false,"bio":"Building tools for doing data science. {📊, 💻, 🛠️}.","customStyleSheet":null,"socialStats":{"__typename":"SocialStats","followerCount":421},"isBlocking":false,"isMuting":false,"isFollowing":false,"allowNotes":true,"newsletterV3":null,"viewerIsUser":false,"twitterScreenName":""},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":[],"maxUnlockCount":3,"unlocksRemaining":3},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"CustomStyleSheet:8001c43898e8":{"id":"8001c43898e8","__typename":"CustomStyleSheet","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}},"header":{"__typename":"HeaderStyles","backgroundColor":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"rgb":"355876","alpha":"ff"},"postBackgroundColor":null,"headerScale":"HEADER_SCALE_MEDIUM","horizontalAlignment":"START","backgroundImageDisplayMode":"IMAGE_DISPLAY_MODE_FILL","backgroundImageVerticalAlignment":"START","backgroundColorDisplayMode":"COLOR_DISPLAY_MODE_SOLID","secondaryBackgroundColor":null,"backgroundImage":null,"nameColor":null,"nameTreatment":"NAME_TREATMENT_LOGO","postNameTreatment":"NAME_TREATMENT_LOGO","logoImage":{"__ref":"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png"},"logoScale":"HEADER_SCALE_MEDIUM","taglineColor":{"__typename":"ColorValue","rgb":"ffffff","alpha":"ff"},"taglineTreatment":"TAGLINE_TREATMENT_HEADER"},"navigation":{"__typename":"HeaderNavigation","navItems":[{"__typename":"HeaderNavigationItem","name":"Editors' Picks","href":"https:\u002F\u002Ftowardsdatascience.com\u002Ftagged\u002Feditors-pick?fromNav=true","tagSlugs":[],"type":"NAV_TYPE_LINK"},{"__typename":"HeaderNavigationItem","name":"Features","href":"https:\u002F\u002Ftowardsdatascience.com\u002Ftagged\u002Ftds-features?fromNav=true","tagSlugs":[],"type":"NAV_TYPE_LINK"},{"__typename":"HeaderNavigationItem","name":"Explore","href":"https:\u002F\u002Ftowardsdatascience.com\u002Ftagged\u002Ftds-explore?fromNav=true","tagSlugs":[],"type":"NAV_TYPE_LINK"},{"__typename":"HeaderNavigationItem","name":"Contribute","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fquestions-96667b06af5","tagSlugs":[],"type":"NAV_TYPE_LINK"}]},"postBody":null,"postBodyOLI":null,"postBodyULI":null,"postBodyIframe":null,"postBodyImage":null,"postHeaderTitle":null,"postHeaderSubtitle":null,"postHeaderKicker":null,"postBodyP":null,"postBodyBQ":null,"postBodyPQ":null,"postBodyH2":null,"postBodyH3":null,"postBodyHR":null,"postBodyPRE":null},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","__typename":"ImageMetadata","originalWidth":337,"originalHeight":122},"User:895063a310f4":{"id":"895063a310f4","__typename":"User"},"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png":{"id":"1*hVxgUA6kP-PgL5TJjuyePg.png","__typename":"ImageMetadata"},"NewsletterV3:d6fe9076899":{"id":"d6fe9076899","__typename":"NewsletterV3","slug":"the-daily-pick","isSubscribed":false,"showPromo":true,"name":"The Daily Pick","description":"Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.","type":"NEWSLETTER_TYPE_COLLECTION","user":{"__typename":"User","name":"Ludovic Benistant"},"collection":{"__ref":"Collection:7f60cf5620c9"}},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","__typename":"Collection","domain":"towardsdatascience.com","googleAnalyticsId":null,"slug":"towards-data-science","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraVisible":true,"favicon":{"__ref":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png"},"name":"Towards Data Science","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:8001c43898e8"},"tagline":"A Medium publication sharing concepts, ideas, and codes.","isAuroraEligible":true,"viewerIsEditor":false,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"navItems":[{"__typename":"NavItem","title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM"}],"creator":{"__ref":"User:895063a310f4"},"subscriberCount":533143,"avatar":{"__ref":"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png"},"isEnrolledInHightower":false,"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"viewerIsMuting":false,"viewerCanEditOwnPosts":true,"viewerCanEditPosts":false,"description":"A Medium publication sharing concepts, ideas, and codes.","ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null},"ImageMetadata:1*AGyTPCaRzVqL77kFwUwHKg.png":{"id":"1*AGyTPCaRzVqL77kFwUwHKg.png","__typename":"ImageMetadata","originalWidth":1376,"originalHeight":429},"Paragraph:7217f6ca062f_0":{"id":"7217f6ca062f_0","__typename":"Paragraph","name":"ae58","text":"Photo by Blake Weyland on Unsplash","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*TnSDLVixRZfGZksBLT7kMA.jpeg"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":9,"end":22,"type":"A","href":"https:\u002F\u002Funsplash.com\u002Fphotos\u002F9hhOVsf1lpU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":26,"end":34,"type":"A","href":"https:\u002F\u002Funsplash.com\u002Fsearch\u002Fphotos\u002Fmatryoshka?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_1":{"id":"7217f6ca062f_1","__typename":"Paragraph","name":"052e","text":"Boost your CNN image classifier performance with progressive resizing in Keras","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_2":{"id":"7217f6ca062f_2","__typename":"Paragraph","name":"e741","text":"If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of neural network which build progressively higher level features out of groups of pixels commonly found in the images. How an image scores on these features is then weighted to generate a final classification result. CNNs are the best image classifier algorithm we know of, and they work particularly well when given lots and lots of data to work with.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":75,"end":103,"type":"A","href":"https:\u002F\u002Fmedium.freecodecamp.org\u002Fan-intuitive-guide-to-convolutional-neural-networks-260c2de0a050","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_3":{"id":"7217f6ca062f_3","__typename":"Paragraph","name":"740e","text":"Progressive resizing is a technique for building CNNs that can be very helpful during the training and optimization phases of a machine learning project. The technique appears most prominently in Jeremy Howard’s work, and he uses it to good effect throughout his terrific fast.ai course, “Deep Learning for Coders”.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":272,"end":279,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":289,"end":313,"type":"A","href":"https:\u002F\u002Fcourse.fast.ai\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":21,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_4":{"id":"7217f6ca062f_4","__typename":"Paragraph","name":"5023","text":"In this article I’ll demonstrate how you can use progressive resizing to build an image classifier using Keras. Specifically, we’ll using progressive resizing to build a CNN that learns to distinguish between 12 different kinds of fruits in what I call the Open Fruits dataset — an image corpus I built based on the Google Open Images dataset (to learn more about Google Open Images, read “How to classify photos in 600 classes using nine million open images”).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":105,"end":110,"type":"A","href":"https:\u002F\u002Fkeras.io\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":390,"end":458,"type":"A","href":"https:\u002F\u002Fblog.quiltdata.com\u002Fhow-to-classify-photos-in-600-classes-using-nine-million-open-images-3cdb989ad1c2","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_5":{"id":"7217f6ca062f_5","__typename":"Paragraph","name":"4a9c","text":"You can follow along with the code and learn how to download the data on GitHub.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":70,"end":79,"type":"A","href":"https:\u002F\u002Fgithub.com\u002FResidentMario\u002Fprogressive-resizing","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_6":{"id":"7217f6ca062f_6","__typename":"Paragraph","name":"af3a","text":"This post assumes familiarity with CNNs. If you’re unfamiliar, Brandon Rohrer’s “How convolutional neural networks work” is excellent background reading.","type":"BQ","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":81,"end":119,"type":"A","href":"https:\u002F\u002Fbrohrer.github.io\u002Fhow_convolutional_neural_networks_work.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_7":{"id":"7217f6ca062f_7","__typename":"Paragraph","name":"5e32","text":"Checking out the data","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_8":{"id":"7217f6ca062f_8","__typename":"Paragraph","name":"e6eb","text":"Recall that our dataset consists of images of 12 different kinds of fruits taken from Google Open Images, which is in turn based on permissively-licensed images from Flickr. To get a taste, here’s 25 random images from the dataset:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":86,"end":104,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fopenimages\u002Fdataset","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":166,"end":172,"type":"A","href":"https:\u002F\u002Fwww.flickr.com\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_9":{"id":"7217f6ca062f_9","__typename":"Paragraph","name":"e7a1","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7d0EAGgLTtrGFp5EvMtDLA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_10":{"id":"7217f6ca062f_10","__typename":"Paragraph","name":"3ce8","text":"Right away we see that this dataset is very problematic. It includes tiny images; occluded images that only depict parts of the sample; samples depicting groups of objects instead of individual ones; and bounding boxes that are just plain noisy and may not even be constrained to a single type of fruit. In a few of the cases it’s difficult even for a human to distinguish what the target class is.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_11":{"id":"7217f6ca062f_11","__typename":"Paragraph","name":"8513","text":"To add to the difficulty, the dataset is highly imbalanced, with some image classes appearing far more often than others:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_12":{"id":"7217f6ca062f_12","__typename":"Paragraph","name":"dd45","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*zOdNhSVX1EkBNTavpk79Hw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_13":{"id":"7217f6ca062f_13","__typename":"Paragraph","name":"9011","text":"Between the low image and label quality and the class sparsity this classification problem is a very, very difficult one.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_14":{"id":"7217f6ca062f_14","__typename":"Paragraph","name":"5b00","text":"Start small to iterate quickly","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_15":{"id":"7217f6ca062f_15","__typename":"Paragraph","name":"9344","text":"Now that we understand the contents of our dataset, we need to make choices about the network we will train.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_16":{"id":"7217f6ca062f_16","__typename":"Paragraph","name":"5626","text":"One trouble is that a single neural network can only work with standardly-sized images; too-small images must be scaled up and too-large images must be scaled down. But what image size should be pick?","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_17":{"id":"7217f6ca062f_17","__typename":"Paragraph","name":"d299","text":"If your goal is model accuracy, larger is obviously better. But there is a lot of advantage to starting small.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":60,"end":109,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_18":{"id":"7217f6ca062f_18","__typename":"Paragraph","name":"fb6a","text":"To understand why, we must first understand that the most important features of an image classification problem are “large”. Properly tuned gradient descent naturally favors robust, well-supported features in its decision-making. In the image classification case this translates into features occupying as many pixels in as many of the sample images as possible.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_19":{"id":"7217f6ca062f_19","__typename":"Paragraph","name":"7e3f","text":"For example, suppose we teach a neural network to distinguish between oranges and apples. Suppose that one model classifies by distinguishing between “orange” and “red”, and another classifies by distinguishing between “stem shaped like an orange stem” and “stem shaped like an apple stem”. The first model is robust: any image we score, no matter how small or misshaped, will have orange pixels and red pixels usable by the model. The second model is not: we can image images so small that the stems are not easily distinguishable, or images with the stem cropped out, or images where the stems have been removed outright.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":318,"end":322,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_20":{"id":"7217f6ca062f_20","__typename":"Paragraph","name":"6f8c","text":"The practical result is that while a model trained on very small images will learn fewer features than one trained on very large images, the ones that it does learn will be the most important ones. Thus a model architecture that works on small images will generalize to larger ones.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":154,"end":159,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_21":{"id":"7217f6ca062f_21","__typename":"Paragraph","name":"2c66","text":"Meanwhile, small-image models are much faster to train. After all an image input size twice as large has four times as many pixels to learn on!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":34,"end":39,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_22":{"id":"7217f6ca062f_22","__typename":"Paragraph","name":"8e1e","text":"Since small-image models generalize well to larger input sizes, and since they take less time to train, and since the first batch of models we build are going to be highly experimental anyway, why don’t we save time and just train our first few models on small data, and worry about scaling up the images and the models later?","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_23":{"id":"7217f6ca062f_23","__typename":"Paragraph","name":"0a98","text":"In fact, that is exactly what progressive resizing is!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":17,"end":24,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_24":{"id":"7217f6ca062f_24","__typename":"Paragraph","name":"8829","text":"We now understand the main idea behind progressive resizing. Let’s see how it works in practice.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_25":{"id":"7217f6ca062f_25","__typename":"Paragraph","name":"cf33","text":"Our first tiny model","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_26":{"id":"7217f6ca062f_26","__typename":"Paragraph","name":"13ad","text":"We start out by building our first small-scale model.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_27":{"id":"7217f6ca062f_27","__typename":"Paragraph","name":"55f8","text":"Here is a smoothed kernel-density plot of image sizes in our “Open Fruits” dataset:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":19,"end":38,"type":"A","href":"https:\u002F\u002Fseaborn.pydata.org\u002Fgenerated\u002Fseaborn.kdeplot.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_28":{"id":"7217f6ca062f_28","__typename":"Paragraph","name":"b85e","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*kta4aX_8Dl5IYt9-Zo8bdw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_29":{"id":"7217f6ca062f_29","__typename":"Paragraph","name":"3db5","text":"We see here that the images peak at around 128x128 in size. So for our initial input size we will choose 1\u002F3 of that: 48x48.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":43,"end":50,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":118,"end":123,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_30":{"id":"7217f6ca062f_30","__typename":"Paragraph","name":"c664","text":"Now it’s time to experiment! What kind of model you end up building in this phase of the project is entirely up to you. Here’s what I did (with comments in the code):","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_31":{"id":"7217f6ca062f_31","__typename":"Paragraph","name":"f1a3","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:51bc57f40d090a4155d633ad7e1364ed"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_32":{"id":"7217f6ca062f_32","__typename":"Paragraph","name":"66af","text":"This model achieved ~53% validation accuracy:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_33":{"id":"7217f6ca062f_33","__typename":"Paragraph","name":"a4b6","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*jlSwmz5yZyLLIHgwPlu_-w.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_34":{"id":"7217f6ca062f_34","__typename":"Paragraph","name":"f25e","text":"Not stellar, but remember, this is a very simple model trained on very small very noisy images, with a lot of classes to choose from. We could do better by working on this model further, but I only had so much time to iterate on this model. 😅","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_35":{"id":"7217f6ca062f_35","__typename":"Paragraph","name":"ac38","text":"Applying progressive resizing","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_36":{"id":"7217f6ca062f_36","__typename":"Paragraph","name":"833d","text":"We now apply progressive resizing to the problem.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_37":{"id":"7217f6ca062f_37","__typename":"Paragraph","name":"a6fd","text":"We started by building a classifier that performs well on tiny n x n (48 x 48) images. The next step is scaling our model up to 2n x 2n (96 x 96) images.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":63,"end":68,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":128,"end":135,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_38":{"id":"7217f6ca062f_38","__typename":"Paragraph","name":"f2cf","text":"We do this using transfer learning. Transfer learning is the technique of re-using layers and weights from previous models when building new ones (“Deep Learning For Beginners Using Transfer Learning In Keras” provides a good overview). In our case, this will mean taking the model we just built, freezing it (so that further training won’t make any changes to our existing weights), and injecting its layers into a new model (one which takes upscaled 96 x 96 images as input).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":148,"end":208,"type":"A","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fkeras-transfer-learning-for-beginners-6c9b8b7143e","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":17,"end":34,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_39":{"id":"7217f6ca062f_39","__typename":"Paragraph","name":"1ce7","text":"The work we do at this stage is limited to finding a configuration of good “feeder layers” we can prefix our old model with. These new layers can focus on finding the additional features findable in 96 x 96 pixels that weren’t in 48 x 48 pixels.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_40":{"id":"7217f6ca062f_40","__typename":"Paragraph","name":"9188","text":"First I saved the 48 x 48 model to disk as model-48.h5. Then I created the following new model:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":43,"end":54,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_41":{"id":"7217f6ca062f_41","__typename":"Paragraph","name":"4692","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:5ac2e3d59880a07e516763c68e67b327"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_42":{"id":"7217f6ca062f_42","__typename":"Paragraph","name":"2285","text":"This script:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_43":{"id":"7217f6ca062f_43","__typename":"Paragraph","name":"24e1","text":"Downloads and instantiates our old 48 x 48 model.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_44":{"id":"7217f6ca062f_44","__typename":"Paragraph","name":"a7c8","text":"Instantiates a new model with two new 96 x 96 convolutional layers.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_45":{"id":"7217f6ca062f_45","__typename":"Paragraph","name":"acaf","text":"Appends a max pooling layer, which downsamples 96 x 96 → 48 x 48—the expected input size for our old model.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_46":{"id":"7217f6ca062f_46","__typename":"Paragraph","name":"deeb","text":"Removes the first convolutional layer from our old model (by the way, this helps reduce overfit!).","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_47":{"id":"7217f6ca062f_47","__typename":"Paragraph","name":"77fe","text":"Reattaches the rest of the layers of our old model onto the new one.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_48":{"id":"7217f6ca062f_48","__typename":"Paragraph","name":"37a0","text":"Freezes the old convolutional and fully-connected layer weights in place.","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_49":{"id":"7217f6ca062f_49","__typename":"Paragraph","name":"9624","text":"Basically, we’ve created a new model that trains on 96x96 pixel images which reuses our old 48 x 48 classifier internally!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":71,"end":121,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_50":{"id":"7217f6ca062f_50","__typename":"Paragraph","name":"609c","text":"This new model improves performance from ~53% to ~59%:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_51":{"id":"7217f6ca062f_51","__typename":"Paragraph","name":"ff26","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*bzyfBZvwWEO50DLwpMc0xA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_52":{"id":"7217f6ca062f_52","__typename":"Paragraph","name":"664b","text":"We can apply progressive resizing one more time, this time moving from 96x96 to 192x192. The procedure required is the same, differing only in scale:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_53":{"id":"7217f6ca062f_53","__typename":"Paragraph","name":"b4e1","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:a477998b59a06e6a8a3ac2d71fc76dca"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_54":{"id":"7217f6ca062f_54","__typename":"Paragraph","name":"ee8e","text":"This new model sees data that is fully sixteen times as large as our original tiny 48x48 model. This translates into further model improvement, but this time that benefit is more modest — up from 59% to 61%:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_55":{"id":"7217f6ca062f_55","__typename":"Paragraph","name":"b0dc","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*RWQ34_N1fBYjOV6OfGQTSA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_56":{"id":"7217f6ca062f_56","__typename":"Paragraph","name":"8554","text":"To summarize what we’ve done:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_57":{"id":"7217f6ca062f_57","__typename":"Paragraph","name":"7578","text":"We started with a model that trained on tiny 48x48 pixel images, which is 53% accurate.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_58":{"id":"7217f6ca062f_58","__typename":"Paragraph","name":"14e5","text":"Next we trained a model on 96x96 pixel images, reusing our 48x48 classifier within our model and achieving 59% accuracy.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_59":{"id":"7217f6ca062f_59","__typename":"Paragraph","name":"2518","text":"Finally, we trained a model on 192x192 pixel images, reusing our 96x96 classifier (which in turn reused our 48x48 classifier!) and achieving 61% accuracy.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_60":{"id":"7217f6ca062f_60","__typename":"Paragraph","name":"7458","text":"Note that, in the interest of time, I did not spend much time experimenting with the new layers I added in steps 2 and 3. To improve performance further, here are some other things you could try:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_61":{"id":"7217f6ca062f_61","__typename":"Paragraph","name":"d12e","text":"Increasing or decreasing the number of new convolutional layers you add.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_62":{"id":"7217f6ca062f_62","__typename":"Paragraph","name":"1b95","text":"Increasing or decreasing the number of nodes in each new convolutional layer.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_63":{"id":"7217f6ca062f_63","__typename":"Paragraph","name":"bed3","text":"Tuning hyper-parameters like activation functions and learning rates.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_64":{"id":"7217f6ca062f_64","__typename":"Paragraph","name":"23a6","text":"Experimenting with the image preprocessing you apply.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_65":{"id":"7217f6ca062f_65","__typename":"Paragraph","name":"254f","text":"Unfreezing the fully-connected layer and adjusting\u002Ftraining that as well.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_66":{"id":"7217f6ca062f_66","__typename":"Paragraph","name":"5c09","text":"Unfreezing one or more preexisting convolutional layers and (re-)training those as well.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_67":{"id":"7217f6ca062f_67","__typename":"Paragraph","name":"fa3a","text":"Conclusion","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_68":{"id":"7217f6ca062f_68","__typename":"Paragraph","name":"28e7","text":"We started this article off by discussing the fact that convolutional neural networks trained on small images are both fast and easy to train and readily generalizable to larger image inputs. This makes them good models to build during the early experimental phase of a project, when you’re still just trying to get to grips with a basic network architecture that works well. We can concentrate on dashing off quick one-off models now, and on scaling them up and fine-tuning performance later. Finally, we heard that models trained this way can often achieve equal or better performance than models trained from scratch.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:7217f6ca062f_69":{"id":"7217f6ca062f_69","__typename":"Paragraph","name":"dfff","text":"Consider the alternative: building and tuning a full-sized 196 x 196 model from the start. This model would have an unrestricted “model finding space”: it could theoretically converge on any combination of layer weights that works best for the given problem. Progressive resizing is much more restrictive: it require that a model that works well on 2n x 2n images must subsume a model that works well on n x n.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":349,"end":356,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":404,"end":409,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_70":{"id":"7217f6ca062f_70","__typename":"Paragraph","name":"b737","text":"This could in theory mean that we “miss” an even better architecture that a model built from scratch could converge on. But in practice, models built using progressive resizing principles often actually do better than models built from scratch.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":206,"end":213,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_71":{"id":"7217f6ca062f_71","__typename":"Paragraph","name":"e9cd","text":"The theoretical reason why is a mystery. One compelling theory, courtesy of Miguel Perez Michaus, is that it improves the ability of the model to learn “scale-dependent” patterns. He writes about this in the excellent blog post “Yes, Convolutional Neural Nets do care about Scale”; I recommend reading it if you want to learn more.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":229,"end":279,"type":"A","href":"https:\u002F\u002Fmiguel-data-sc.github.io\u002F2017-11-23-second\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:7217f6ca062f_72":{"id":"7217f6ca062f_72","__typename":"Paragraph","name":"42c1","text":"Nevertheless, progressive resizing is an interesting technique and a useful approach to image modeling problems And hopefully now that you have read this article, another useful tool in your deep learning toolbox. 😎","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"ImageMetadata:1*TnSDLVixRZfGZksBLT7kMA.jpeg":{"id":"1*TnSDLVixRZfGZksBLT7kMA.jpeg","__typename":"ImageMetadata","originalHeight":2000,"originalWidth":4950,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*7d0EAGgLTtrGFp5EvMtDLA.png":{"id":"1*7d0EAGgLTtrGFp5EvMtDLA.png","__typename":"ImageMetadata","originalHeight":1122,"originalWidth":1166,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*zOdNhSVX1EkBNTavpk79Hw.png":{"id":"1*zOdNhSVX1EkBNTavpk79Hw.png","__typename":"ImageMetadata","originalHeight":575,"originalWidth":735,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*kta4aX_8Dl5IYt9-Zo8bdw.png":{"id":"1*kta4aX_8Dl5IYt9-Zo8bdw.png","__typename":"ImageMetadata","originalHeight":494,"originalWidth":759,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:51bc57f40d090a4155d633ad7e1364ed":{"id":"51bc57f40d090a4155d633ad7e1364ed","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"vgg-48-128.py"},"ImageMetadata:1*jlSwmz5yZyLLIHgwPlu_-w.png":{"id":"1*jlSwmz5yZyLLIHgwPlu_-w.png","__typename":"ImageMetadata","originalHeight":600,"originalWidth":800,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:5ac2e3d59880a07e516763c68e67b327":{"id":"5ac2e3d59880a07e516763c68e67b327","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"vgg-96-define-model.py"},"ImageMetadata:1*bzyfBZvwWEO50DLwpMc0xA.png":{"id":"1*bzyfBZvwWEO50DLwpMc0xA.png","__typename":"ImageMetadata","originalHeight":600,"originalWidth":800,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:a477998b59a06e6a8a3ac2d71fc76dca":{"id":"a477998b59a06e6a8a3ac2d71fc76dca","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"vgg-192-define-model.py"},"ImageMetadata:1*RWQ34_N1fBYjOV6OfGQTSA.png":{"id":"1*RWQ34_N1fBYjOV6OfGQTSA.png","__typename":"ImageMetadata","originalHeight":600,"originalWidth":800,"focusPercentX":null,"focusPercentY":null,"alt":null},"Tag:machine-learning":{"id":"machine-learning","__typename":"Tag","displayTitle":"Machine Learning"},"Tag:keras":{"id":"keras","__typename":"Tag","displayTitle":"Keras"},"Tag:cnn":{"id":"cnn","__typename":"Tag","displayTitle":"Cnn"},"Tag:optimization":{"id":"optimization","__typename":"Tag","displayTitle":"Optimization"},"Tag:fastai":{"id":"fastai","__typename":"Tag","displayTitle":"Fastai"},"Post:a7d96da06e20":{"id":"a7d96da06e20","__typename":"Post","canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fmedium.com\u002Fme\u002Fstories\u002Fpublic\"}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","isCacheableContent":false,"bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:7217f6ca062f_0"},{"__ref":"Paragraph:7217f6ca062f_1"},{"__ref":"Paragraph:7217f6ca062f_2"},{"__ref":"Paragraph:7217f6ca062f_3"},{"__ref":"Paragraph:7217f6ca062f_4"},{"__ref":"Paragraph:7217f6ca062f_5"},{"__ref":"Paragraph:7217f6ca062f_6"},{"__ref":"Paragraph:7217f6ca062f_7"},{"__ref":"Paragraph:7217f6ca062f_8"},{"__ref":"Paragraph:7217f6ca062f_9"},{"__ref":"Paragraph:7217f6ca062f_10"},{"__ref":"Paragraph:7217f6ca062f_11"},{"__ref":"Paragraph:7217f6ca062f_12"},{"__ref":"Paragraph:7217f6ca062f_13"},{"__ref":"Paragraph:7217f6ca062f_14"},{"__ref":"Paragraph:7217f6ca062f_15"},{"__ref":"Paragraph:7217f6ca062f_16"},{"__ref":"Paragraph:7217f6ca062f_17"},{"__ref":"Paragraph:7217f6ca062f_18"},{"__ref":"Paragraph:7217f6ca062f_19"},{"__ref":"Paragraph:7217f6ca062f_20"},{"__ref":"Paragraph:7217f6ca062f_21"},{"__ref":"Paragraph:7217f6ca062f_22"},{"__ref":"Paragraph:7217f6ca062f_23"},{"__ref":"Paragraph:7217f6ca062f_24"},{"__ref":"Paragraph:7217f6ca062f_25"},{"__ref":"Paragraph:7217f6ca062f_26"},{"__ref":"Paragraph:7217f6ca062f_27"},{"__ref":"Paragraph:7217f6ca062f_28"},{"__ref":"Paragraph:7217f6ca062f_29"},{"__ref":"Paragraph:7217f6ca062f_30"},{"__ref":"Paragraph:7217f6ca062f_31"},{"__ref":"Paragraph:7217f6ca062f_32"},{"__ref":"Paragraph:7217f6ca062f_33"},{"__ref":"Paragraph:7217f6ca062f_34"},{"__ref":"Paragraph:7217f6ca062f_35"},{"__ref":"Paragraph:7217f6ca062f_36"},{"__ref":"Paragraph:7217f6ca062f_37"},{"__ref":"Paragraph:7217f6ca062f_38"},{"__ref":"Paragraph:7217f6ca062f_39"},{"__ref":"Paragraph:7217f6ca062f_40"},{"__ref":"Paragraph:7217f6ca062f_41"},{"__ref":"Paragraph:7217f6ca062f_42"},{"__ref":"Paragraph:7217f6ca062f_43"},{"__ref":"Paragraph:7217f6ca062f_44"},{"__ref":"Paragraph:7217f6ca062f_45"},{"__ref":"Paragraph:7217f6ca062f_46"},{"__ref":"Paragraph:7217f6ca062f_47"},{"__ref":"Paragraph:7217f6ca062f_48"},{"__ref":"Paragraph:7217f6ca062f_49"},{"__ref":"Paragraph:7217f6ca062f_50"},{"__ref":"Paragraph:7217f6ca062f_51"},{"__ref":"Paragraph:7217f6ca062f_52"},{"__ref":"Paragraph:7217f6ca062f_53"},{"__ref":"Paragraph:7217f6ca062f_54"},{"__ref":"Paragraph:7217f6ca062f_55"},{"__ref":"Paragraph:7217f6ca062f_56"},{"__ref":"Paragraph:7217f6ca062f_57"},{"__ref":"Paragraph:7217f6ca062f_58"},{"__ref":"Paragraph:7217f6ca062f_59"},{"__ref":"Paragraph:7217f6ca062f_60"},{"__ref":"Paragraph:7217f6ca062f_61"},{"__ref":"Paragraph:7217f6ca062f_62"},{"__ref":"Paragraph:7217f6ca062f_63"},{"__ref":"Paragraph:7217f6ca062f_64"},{"__ref":"Paragraph:7217f6ca062f_65"},{"__ref":"Paragraph:7217f6ca062f_66"},{"__ref":"Paragraph:7217f6ca062f_67"},{"__ref":"Paragraph:7217f6ca062f_68"},{"__ref":"Paragraph:7217f6ca062f_69"},{"__ref":"Paragraph:7217f6ca062f_70"},{"__ref":"Paragraph:7217f6ca062f_71"},{"__ref":"Paragraph:7217f6ca062f_72"}],"sections":[{"__typename":"Section","name":"ae15","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"creator":{"__ref":"User:b6d2cfb88f3"},"customStyleSheet":{"__ref":"CustomStyleSheet:8001c43898e8"},"firstPublishedAt":1554163973825,"isLocked":false,"isPublished":true,"isShortform":false,"layerCake":4,"primaryTopic":{"__typename":"Topic","name":"Machine Learning","slug":"machine-learning","isFollowing":null},"title":"Boost your CNN image classifier performance with progressive resizing in Keras","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fboost-your-cnn-image-classifier-performance-with-progressive-resizing-in-keras-a7d96da06e20","isLimitedState":false,"visibility":"PUBLIC","license":"ALL_RIGHTS_RESERVED","allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:machine-learning"},{"__ref":"Tag:keras"},{"__ref":"Tag:cnn"},{"__ref":"Tag:optimization"},{"__ref":"Tag:fastai"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning","slug":"machine-learning"}],"viewerClapCount":0,"showSubscribeToProfilePromo":false,"showSubscribeToCollectionNewsletterV3Promo":true,"inResponseToPostResult":null,"isNewsletter":false,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1554163973825,"readingTime":7.823584905660377,"previewContent":{"__typename":"PreviewContent","subtitle":"If you’re building an image classifier these days, you’re probably using a convolutional neural network to do it. CNNs are a type of…"},"previewImage":{"__ref":"ImageMetadata:1*TnSDLVixRZfGZksBLT7kMA.jpeg"},"creatorPartnerProgramEnrollmentStatus":"NOT_ENROLLED","clapCount":1405,"lockedSource":"LOCKED_POST_SOURCE_NONE","isSuspended":false,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"pinnedByCreatorAt":0,"curationEligibleAt":0,"shareKey":"43fd996bfa370ddafb469c5b50900138","responsesCount":8,"collaborators":[],"translationSourcePost":null,"inResponseToMediaResource":null,"isDistributionAlertDismissed":false,"audioVersionUrl":"","seoTitle":"","updatedAt":1603149127889,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","postResponses":{"__typename":"PostResponses","count":8},"latestPublishedVersion":"7217f6ca062f","isPublishToEmail":false,"readingList":"READING_LIST_NONE","voterCount":298,"recommenders":[]}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.9f0a59eb.js"></script><script src="https://cdn-client.medium.com/lite/static/js/4739.78fb2a04.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.6b01daef.js"></script><script src="https://cdn-client.medium.com/lite/static/js/5573.159bf40f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/instrumentation.b5262cb2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.2d4858fa.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1826.f1c2fa77.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4464.c01c0ad8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8342.6aa0b45e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1148.27bc51ff.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5064.fedfa9f1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9274.431d8f19.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2846.2eab6f86.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7012.5f022c24.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7993.d921811a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6839.76c7a097.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5127.25f1bb68.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5967.577a90dd.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8751.0b0595e4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6010.0c79e639.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7131.65798e19.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9809.2014403c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9978.10a970d1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7106.32df7fe7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3277.e57d6ad0.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3721.34f2c2c7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2514.34c0377a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2602.6f7e7156.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1304.124bf019.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6098.d8904caa.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8578.935a6d3a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9889.79178434.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3981.14502e6d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/Post.8a4e777c.chunk.js"></script><script>window.main();</script></body></html>